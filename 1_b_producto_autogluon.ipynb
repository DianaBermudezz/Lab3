{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2277113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ’¬ Instalar AutoGluon si es necesario\n",
    "#%pip install autogluon.timeseries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc, os, shutil\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bd6f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_safe(numerator: pd.Series, denominator: pd.Series, dtype='float32', fillna=None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calcula un porcentaje seguro como numerator / denominator.\n",
    "    - Reemplaza divisiones por cero o NaN con NaN.\n",
    "    - Opcionalmente convierte a float32.\n",
    "    - Puede rellenar NaNs con `fillna`.\n",
    "    \"\"\"\n",
    "    result = (numerator / denominator).mask((denominator == 0) | (denominator.isna()))\n",
    "    if fillna is not None:\n",
    "        result = result.fillna(fillna)\n",
    "    return result.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6aa29c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\"Itera por las columnas del DataFrame y modifica el tipo de datos para reducir uso de memoria.\"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Uso de memoria inicial del DataFrame: {start_mem:.2f} MB')\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(col_type):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if pd.api.types.is_integer_dtype(col_type):\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            # SÃ³lo convertir a categorÃ­a si no lo es ya\n",
    "            if not pd.api.types.is_categorical_dtype(df[col]):\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Uso de memoria final del DataFrame: {end_mem:.2f} MB')\n",
    "    print(f'Memoria reducida en un {(100 * (start_mem - end_mem) / start_mem):.2f}%')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eebc6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"01_producto_base.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba540657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uso de memoria inicial del DataFrame: 18.41 MB\n",
      "Uso de memoria final del DataFrame: 18.20 MB\n",
      "Memoria reducida en un 1.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\3492438140.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(df[col]):\n",
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\3492438140.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(df[col]):\n",
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\3492438140.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(df[col]):\n"
     ]
    }
   ],
   "source": [
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b7bdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31522, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8080c1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201702</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201703</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201704</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201705</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  product_id\n",
       "0   201701       20001\n",
       "1   201702       20001\n",
       "2   201703       20001\n",
       "3   201704       20001\n",
       "4   201705       20001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['periodo','product_id']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66af56f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\2741242683.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['timestamp'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\2741242683.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['item_id'] = df['product_id']\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_141401'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       3.62 GB / 15.69 GB (23.1%)\n",
      "Disk Space Avail:   154.99 GB / 459.95 GB (33.7%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 5355 rows, 765 time series. Median time series length is 7 (min=7, max=7). \n",
      "Time series in train_data are too short for chosen num_val_windows=2. Reducing num_val_windows to 1.\n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['cat_delta_tn_lag_10', 'cat_delta_tn_lag_11', 'cat_delta_tn_lag_12', 'cat_delta_tn_lag_13', 'cat_delta_tn_lag_7', 'cat_delta_tn_lag_8', 'cat_delta_tn_lag_9', 'cat_season_yearly', 'cat_total_delta_media_movil_12', 'cat_total_delta_min_movil_12', 'cat_total_delta_std_movil_12', 'cat_total_tn_lag_10', 'cat_total_tn_lag_11', 'cat_total_tn_lag_12', 'cat_total_tn_lag_13', 'cat_total_tn_lag_7', 'cat_total_tn_lag_8', 'cat_total_tn_lag_9', 'cat_total_tn_ma_12', 'cat_total_tn_min_12', 'cat_total_tn_std_12', 'cat_trend', 'delta_media_movil_9', 'delta_min_movil_9', 'delta_std_movil_9', 'delta_tn_10', 'delta_tn_11', 'delta_tn_12', 'delta_tn_13', 'delta_tn_14', 'delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'delta_tn_7', 'delta_tn_8', 'delta_tn_9', 'meses_vida_producto', 'otros_avg_lag10', 'otros_avg_lag11', 'otros_avg_lag12', 'otros_avg_lag13', 'otros_avg_lag7', 'otros_avg_lag8', 'otros_avg_lag9', 'otros_total_tn_lag10', 'otros_total_tn_lag11', 'otros_total_tn_lag12', 'otros_total_tn_lag13', 'otros_total_tn_lag7', 'otros_total_tn_lag8', 'otros_total_tn_lag9', 'outlier-2', 'prod_season_yearly', 'prod_trend', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'share_producto_en_categoria_lag_10', 'share_producto_en_categoria_lag_11', 'share_producto_en_categoria_lag_12', 'share_producto_en_categoria_lag_13', 'share_producto_en_categoria_lag_7', 'share_producto_en_categoria_lag_8', 'share_producto_en_categoria_lag_9', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_10', 'tasa_crecimiento_share_producto_en_categoria_lag_11', 'tasa_crecimiento_share_producto_en_categoria_lag_12', 'tasa_crecimiento_share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tasa_crecimiento_share_producto_en_categoria_lag_9', 'tn_lag_10', 'tn_lag_11', 'tn_lag_12', 'tn_lag_13', 'tn_lag_14', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'tn_lag_7', 'tn_lag_8', 'tn_lag_9', 'tn_media_movil_12', 'tn_min_movil_12', 'tn_std_movil_12', 'total_clientes_distintos', 'total_min_tn', 'total_season_yearly', 'total_total_delta_media_movil_12', 'total_total_delta_min_movil_12', 'total_total_delta_std_movil_12', 'total_total_tn_diff_10', 'total_total_tn_diff_11', 'total_total_tn_diff_12', 'total_total_tn_diff_13', 'total_total_tn_diff_7', 'total_total_tn_diff_8', 'total_total_tn_diff_9', 'total_total_tn_lag_10', 'total_total_tn_lag_11', 'total_total_tn_lag_12', 'total_total_tn_lag_13', 'total_total_tn_lag_7', 'total_total_tn_lag_8', 'total_total_tn_lag_9', 'total_total_tn_ma_12', 'total_total_tn_min_12', 'total_total_tn_min_6', 'total_total_tn_std_12', 'total_trend']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 11:14:04\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.8s of remaining time.\n",
      "\t-0.2102       = Validation score (-WQL)\n",
      "\t0.03    s     = Training runtime\n",
      "\t3.52    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.7s of the 3596.3s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.3413       = Validation score (-WQL)\n",
      "\t0.88    s     = Training runtime\n",
      "\t0.08    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.8s of the 3595.3s of remaining time.\n",
      "\t-0.1813       = Validation score (-WQL)\n",
      "\t4.19    s     = Training runtime\n",
      "\t0.12    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 359.1s of the 3591.0s of remaining time.\n",
      "\t-0.2677       = Validation score (-WQL)\n",
      "\t0.04    s     = Training runtime\n",
      "\t0.44    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 398.9s of the 3590.4s of remaining time.\n",
      "\t-0.2314       = Validation score (-WQL)\n",
      "\t0.05    s     = Training runtime\n",
      "\t2.44    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 448.5s of the 3587.9s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 765 time series (100.0%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2102       = Validation score (-WQL)\n",
      "\t0.07    s     = Training runtime\n",
      "\t0.49    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 512.5s of the 3587.3s of remaining time.\n",
      "\t-0.2126       = Validation score (-WQL)\n",
      "\t0.04    s     = Training runtime\n",
      "\t4.55    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 597.1s of the 3582.7s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_141401\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\t-0.1893       = Validation score (-WQL)\n",
      "\t327.82  s     = Training runtime\n",
      "\t0.76    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 663.5s of the 3254.1s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 879.7s of the 3239.2s of remaining time.\n",
      "\t-0.1733       = Validation score (-WQL)\n",
      "\t72.70   s     = Training runtime\n",
      "\t1.06    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1282.7s of the 3165.4s of remaining time.\n",
      "\t-0.1716       = Validation score (-WQL)\n",
      "\t86.70   s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2478.0s of the 3078.0s of remaining time.\n",
      "\t-0.2069       = Validation score (-WQL)\n",
      "\t260.39  s     = Training runtime\n",
      "\t1.21    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.16, 'DeepAR': 0.29, 'DynamicOptimizedTheta': 0.08, 'NPTS': 0.17, 'PatchTST': 0.03, 'TiDE': 0.27}\n",
      "\t-0.1677       = Validation score (-WQL)\n",
      "\t2.68    s     = Training runtime\n",
      "\t6.54    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 786.46 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1677\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_142724'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.87 GB / 15.69 GB (31.1%)\n",
      "Disk Space Avail:   154.80 GB / 459.95 GB (33.7%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 6167 rows, 772 time series. Median time series length is 8 (min=7, max=8). \n",
      "Time series in train_data are too short for chosen num_val_windows=2. Reducing num_val_windows to 1.\n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['cat_delta_tn_lag_10', 'cat_delta_tn_lag_11', 'cat_delta_tn_lag_12', 'cat_delta_tn_lag_13', 'cat_delta_tn_lag_8', 'cat_delta_tn_lag_9', 'cat_season_yearly', 'cat_total_tn_lag_10', 'cat_total_tn_lag_11', 'cat_total_tn_lag_12', 'cat_total_tn_lag_13', 'cat_total_tn_lag_8', 'cat_total_tn_lag_9', 'cat_trend', 'delta_media_movil_9', 'delta_min_movil_9', 'delta_std_movil_9', 'delta_tn_10', 'delta_tn_11', 'delta_tn_12', 'delta_tn_13', 'delta_tn_14', 'delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'delta_tn_8', 'delta_tn_9', 'otros_avg_lag10', 'otros_avg_lag11', 'otros_avg_lag12', 'otros_avg_lag13', 'otros_avg_lag8', 'otros_avg_lag9', 'otros_total_tn_lag10', 'otros_total_tn_lag11', 'otros_total_tn_lag12', 'otros_total_tn_lag13', 'otros_total_tn_lag8', 'otros_total_tn_lag9', 'outlier-2', 'prod_season_yearly', 'prod_trend', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'share_producto_en_categoria_lag_10', 'share_producto_en_categoria_lag_11', 'share_producto_en_categoria_lag_12', 'share_producto_en_categoria_lag_13', 'share_producto_en_categoria_lag_8', 'share_producto_en_categoria_lag_9', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_10', 'tasa_crecimiento_share_producto_en_categoria_lag_11', 'tasa_crecimiento_share_producto_en_categoria_lag_12', 'tasa_crecimiento_share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tasa_crecimiento_share_producto_en_categoria_lag_9', 'tn_lag_10', 'tn_lag_11', 'tn_lag_12', 'tn_lag_13', 'tn_lag_14', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'tn_lag_8', 'tn_lag_9', 'tn_media_movil_12', 'tn_min_movil_12', 'tn_std_movil_12', 'total_clientes_distintos', 'total_min_tn', 'total_season_yearly', 'total_total_tn_diff_10', 'total_total_tn_diff_11', 'total_total_tn_diff_12', 'total_total_tn_diff_13', 'total_total_tn_diff_8', 'total_total_tn_diff_9', 'total_total_tn_lag_10', 'total_total_tn_lag_11', 'total_total_tn_lag_12', 'total_total_tn_lag_13', 'total_total_tn_lag_8', 'total_total_tn_lag_9', 'total_total_tn_min_6', 'total_trend']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 11:27:31\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.6s of remaining time.\n",
      "\t-0.2455       = Validation score (-WQL)\n",
      "\t0.06    s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3599.0s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.3106       = Validation score (-WQL)\n",
      "\t1.32    s     = Training runtime\n",
      "\t0.10    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 327.1s of the 3597.6s of remaining time.\n",
      "\t-0.1931       = Validation score (-WQL)\n",
      "\t5.78    s     = Training runtime\n",
      "\t0.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 359.2s of the 3591.6s of remaining time.\n",
      "\t-0.3036       = Validation score (-WQL)\n",
      "\t0.06    s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 399.0s of the 3590.9s of remaining time.\n",
      "\t-0.2505       = Validation score (-WQL)\n",
      "\t0.13    s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 448.8s of the 3590.1s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 772 time series (100.0%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2455       = Validation score (-WQL)\n",
      "\t0.11    s     = Training runtime\n",
      "\t0.55    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 512.8s of the 3589.5s of remaining time.\n",
      "\t-0.2258       = Validation score (-WQL)\n",
      "\t0.08    s     = Training runtime\n",
      "\t5.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 597.4s of the 3584.1s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_142724\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\t-0.2124       = Validation score (-WQL)\n",
      "\t457.52  s     = Training runtime\n",
      "\t0.72    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 631.5s of the 3125.9s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 836.7s of the 3110.0s of remaining time.\n",
      "\t-0.1710       = Validation score (-WQL)\n",
      "\t63.73   s     = Training runtime\n",
      "\t1.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1222.6s of the 3045.2s of remaining time.\n",
      "\t-0.1745       = Validation score (-WQL)\n",
      "\t194.83  s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2249.7s of the 2849.7s of remaining time.\n",
      "\t-0.1913       = Validation score (-WQL)\n",
      "\t257.89  s     = Training runtime\n",
      "\t1.24    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'DeepAR': 0.56, 'NPTS': 0.05, 'PatchTST': 0.12, 'TiDE': 0.28}\n",
      "\t-0.1655       = Validation score (-WQL)\n",
      "\t2.59    s     = Training runtime\n",
      "\t3.49    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1012.01 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1655\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_144433'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       5.15 GB / 15.69 GB (32.8%)\n",
      "Disk Space Avail:   154.61 GB / 459.95 GB (33.6%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 6998 rows, 782 time series. Median time series length is 9 (min=7, max=9). \n",
      "\tRemoving 27 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 6795 rows, 755 time series. Median time series length is 9 (min=9, max=9). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['cat_delta_tn_lag_10', 'cat_delta_tn_lag_11', 'cat_delta_tn_lag_12', 'cat_delta_tn_lag_13', 'cat_delta_tn_lag_9', 'cat_season_yearly', 'cat_total_tn_lag_10', 'cat_total_tn_lag_11', 'cat_total_tn_lag_12', 'cat_total_tn_lag_13', 'cat_total_tn_lag_9', 'cat_trend', 'delta_media_movil_9', 'delta_min_movil_9', 'delta_std_movil_9', 'delta_tn_10', 'delta_tn_11', 'delta_tn_12', 'delta_tn_13', 'delta_tn_14', 'delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'delta_tn_9', 'meses_vida_producto', 'otros_avg_lag10', 'otros_avg_lag11', 'otros_avg_lag12', 'otros_avg_lag13', 'otros_avg_lag9', 'otros_total_tn_lag10', 'otros_total_tn_lag11', 'otros_total_tn_lag12', 'otros_total_tn_lag13', 'otros_total_tn_lag9', 'outlier-2', 'prod_season_yearly', 'prod_trend', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'share_producto_en_categoria_lag_10', 'share_producto_en_categoria_lag_11', 'share_producto_en_categoria_lag_12', 'share_producto_en_categoria_lag_13', 'share_producto_en_categoria_lag_9', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_10', 'tasa_crecimiento_share_producto_en_categoria_lag_11', 'tasa_crecimiento_share_producto_en_categoria_lag_12', 'tasa_crecimiento_share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tasa_crecimiento_share_producto_en_categoria_lag_9', 'tn_lag_10', 'tn_lag_11', 'tn_lag_12', 'tn_lag_13', 'tn_lag_14', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'tn_lag_9', 'tn_media_movil_12', 'tn_min_movil_12', 'tn_std_movil_12', 'total_clientes_distintos', 'total_min_tn', 'total_season_yearly', 'total_total_tn_diff_10', 'total_total_tn_diff_11', 'total_total_tn_diff_12', 'total_total_tn_diff_13', 'total_total_tn_diff_9', 'total_total_tn_lag_10', 'total_total_tn_lag_11', 'total_total_tn_lag_12', 'total_total_tn_lag_13', 'total_total_tn_lag_9', 'total_total_tn_min_12', 'total_trend']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 11:44:40\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.5s of remaining time.\n",
      "\t-0.2168       = Validation score (-WQL)\n",
      "\t0.70    s     = Training runtime\n",
      "\t1.01    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.8s of the 3597.8s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2869       = Validation score (-WQL)\n",
      "\t2.76    s     = Training runtime\n",
      "\t0.10    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.8s of the 3594.9s of remaining time.\n",
      "\t-0.2002       = Validation score (-WQL)\n",
      "\t11.42   s     = Training runtime\n",
      "\t0.19    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 358.3s of the 3583.2s of remaining time.\n",
      "\t-0.2701       = Validation score (-WQL)\n",
      "\t0.81    s     = Training runtime\n",
      "\t0.64    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 398.0s of the 3581.7s of remaining time.\n",
      "\t-0.2183       = Validation score (-WQL)\n",
      "\t2.84    s     = Training runtime\n",
      "\t0.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 447.3s of the 3578.2s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 755 time series (100.0%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2045       = Validation score (-WQL)\n",
      "\t0.84    s     = Training runtime\n",
      "\t1.05    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 510.9s of the 3576.3s of remaining time.\n",
      "\t-0.2104       = Validation score (-WQL)\n",
      "\t6.33    s     = Training runtime\n",
      "\t4.72    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 594.2s of the 3565.2s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_144433\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_144433\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.1894       = Validation score (-WQL)\n",
      "\t527.51  s     = Training runtime\n",
      "\t0.68    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 609.2s of the 3037.0s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 807.3s of the 3021.8s of remaining time.\n",
      "\t-0.1916       = Validation score (-WQL)\n",
      "\t127.52  s     = Training runtime\n",
      "\t0.96    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1146.6s of the 2893.3s of remaining time.\n",
      "\t-0.1858       = Validation score (-WQL)\n",
      "\t147.15  s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2145.5s of the 2745.5s of remaining time.\n",
      "\t-0.2495       = Validation score (-WQL)\n",
      "\t601.10  s     = Training runtime\n",
      "\t1.73    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.04, 'ChronosFineTuned[bolt_small]': 0.28, 'DirectTabular': 0.03, 'DynamicOptimizedTheta': 0.09, 'NPTS': 0.05, 'PatchTST': 0.51}\n",
      "\t-0.1819       = Validation score (-WQL)\n",
      "\t5.16    s     = Training runtime\n",
      "\t3.78    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1462.44 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1819\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_150915'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.80 GB / 15.69 GB (30.6%)\n",
      "Disk Space Avail:   154.28 GB / 459.95 GB (33.5%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 7802 rows, 788 time series. Median time series length is 10 (min=7, max=10). \n",
      "\tRemoving 27 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 7595 rows, 761 time series. Median time series length is 10 (min=9, max=10). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['cat_delta_tn_lag_10', 'cat_delta_tn_lag_11', 'cat_delta_tn_lag_12', 'cat_delta_tn_lag_13', 'cat_season_yearly', 'cat_total_tn_lag_10', 'cat_total_tn_lag_11', 'cat_total_tn_lag_12', 'cat_total_tn_lag_13', 'cat_trend', 'delta_tn_10', 'delta_tn_11', 'delta_tn_12', 'delta_tn_13', 'delta_tn_14', 'delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'otros_avg_lag10', 'otros_avg_lag11', 'otros_avg_lag12', 'otros_avg_lag13', 'otros_total_tn_lag10', 'otros_total_tn_lag11', 'otros_total_tn_lag12', 'otros_total_tn_lag13', 'outlier-2', 'prod_season_yearly', 'prod_trend', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'share_producto_en_categoria_lag_10', 'share_producto_en_categoria_lag_11', 'share_producto_en_categoria_lag_12', 'share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_10', 'tasa_crecimiento_share_producto_en_categoria_lag_11', 'tasa_crecimiento_share_producto_en_categoria_lag_12', 'tasa_crecimiento_share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_10', 'tn_lag_11', 'tn_lag_12', 'tn_lag_13', 'tn_lag_14', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn', 'total_season_yearly', 'total_total_tn_diff_10', 'total_total_tn_diff_11', 'total_total_tn_diff_12', 'total_total_tn_diff_13', 'total_total_tn_lag_10', 'total_total_tn_lag_11', 'total_total_tn_lag_12', 'total_total_tn_lag_13', 'total_trend']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 12:09:20\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.5s of remaining time.\n",
      "\t-0.2329       = Validation score (-WQL)\n",
      "\t1.10    s     = Training runtime\n",
      "\t0.51    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.8s of the 3597.9s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2695       = Validation score (-WQL)\n",
      "\t2.98    s     = Training runtime\n",
      "\t0.12    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.8s of the 3594.7s of remaining time.\n",
      "\t-0.2370       = Validation score (-WQL)\n",
      "\t20.32   s     = Training runtime\n",
      "\t0.34    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.4s of the 3574.1s of remaining time.\n",
      "\t-0.2882       = Validation score (-WQL)\n",
      "\t0.81    s     = Training runtime\n",
      "\t0.61    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.0s of the 3572.6s of remaining time.\n",
      "\t-0.2299       = Validation score (-WQL)\n",
      "\t0.95    s     = Training runtime\n",
      "\t0.68    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 446.4s of the 3570.9s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 761 time series (100.0%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2265       = Validation score (-WQL)\n",
      "\t0.87    s     = Training runtime\n",
      "\t1.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.9s of the 3569.0s of remaining time.\n",
      "\t-0.2175       = Validation score (-WQL)\n",
      "\t5.50    s     = Training runtime\n",
      "\t4.78    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 593.1s of the 3558.7s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_150915\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_150915\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2372       = Validation score (-WQL)\n",
      "\t525.85  s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 608.1s of the 3032.3s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 808.2s of the 3024.6s of remaining time.\n",
      "\t-0.1901       = Validation score (-WQL)\n",
      "\t93.58   s     = Training runtime\n",
      "\t0.46    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1165.2s of the 2930.5s of remaining time.\n",
      "\t-0.1964       = Validation score (-WQL)\n",
      "\t72.79   s     = Training runtime\n",
      "\t0.18    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2257.5s of the 2857.5s of remaining time.\n",
      "\t-0.2287       = Validation score (-WQL)\n",
      "\t213.12  s     = Training runtime\n",
      "\t0.47    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosZeroShot[bolt_base]': 0.19, 'DeepAR': 0.65, 'PatchTST': 0.16}\n",
      "\t-0.1867       = Validation score (-WQL)\n",
      "\t1.76    s     = Training runtime\n",
      "\t5.42    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 957.73 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1867\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_152525'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       5.43 GB / 15.69 GB (34.6%)\n",
      "Disk Space Avail:   153.90 GB / 459.95 GB (33.5%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 8656 rows, 801 time series. Median time series length is 11 (min=7, max=11). \n",
      "\tRemoving 30 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 8432 rows, 771 time series. Median time series length is 11 (min=9, max=11). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['cat_delta_tn_lag_11', 'cat_delta_tn_lag_12', 'cat_delta_tn_lag_13', 'cat_season_yearly', 'cat_total_tn_lag_11', 'cat_total_tn_lag_12', 'cat_total_tn_lag_13', 'cat_trend', 'delta_tn_11', 'delta_tn_12', 'delta_tn_13', 'delta_tn_14', 'delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'otros_avg_lag11', 'otros_avg_lag12', 'otros_avg_lag13', 'otros_total_tn_lag11', 'otros_total_tn_lag12', 'otros_total_tn_lag13', 'outlier-2', 'prod_season_yearly', 'prod_trend', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'share_producto_en_categoria_lag_11', 'share_producto_en_categoria_lag_12', 'share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_11', 'tasa_crecimiento_share_producto_en_categoria_lag_12', 'tasa_crecimiento_share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_11', 'tn_lag_12', 'tn_lag_13', 'tn_lag_14', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn', 'total_season_yearly', 'total_total_tn_diff_11', 'total_total_tn_diff_12', 'total_total_tn_diff_13', 'total_total_tn_lag_11', 'total_total_tn_lag_12', 'total_total_tn_lag_13', 'total_trend']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 12:25:27\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.8s of remaining time.\n",
      "\t-0.2080       = Validation score (-WQL)\n",
      "\t3.45    s     = Training runtime\n",
      "\t0.33    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.7s of the 3596.0s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2234       = Validation score (-WQL)\n",
      "\t1.90    s     = Training runtime\n",
      "\t0.09    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.7s of the 3594.0s of remaining time.\n",
      "\t-0.2181       = Validation score (-WQL)\n",
      "\t11.95   s     = Training runtime\n",
      "\t0.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 358.2s of the 3581.9s of remaining time.\n",
      "\t-0.2523       = Validation score (-WQL)\n",
      "\t0.52    s     = Training runtime\n",
      "\t0.44    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.9s of the 3580.9s of remaining time.\n",
      "\t-0.1937       = Validation score (-WQL)\n",
      "\t2.13    s     = Training runtime\n",
      "\t0.45    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 447.3s of the 3578.3s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 29 time series (3.8%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.1963       = Validation score (-WQL)\n",
      "\t0.52    s     = Training runtime\n",
      "\t0.64    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 511.0s of the 3577.1s of remaining time.\n",
      "\t-0.1924       = Validation score (-WQL)\n",
      "\t4.19    s     = Training runtime\n",
      "\t4.04    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 594.8s of the 3568.8s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_152525\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_152525\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.1989       = Validation score (-WQL)\n",
      "\t526.92  s     = Training runtime\n",
      "\t0.66    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 610.3s of the 3041.2s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 810.3s of the 3030.9s of remaining time.\n",
      "\t-0.2128       = Validation score (-WQL)\n",
      "\t159.08  s     = Training runtime\n",
      "\t0.59    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1135.6s of the 2871.2s of remaining time.\n",
      "\t-0.1823       = Validation score (-WQL)\n",
      "\t82.14   s     = Training runtime\n",
      "\t0.24    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2188.9s of the 2788.9s of remaining time.\n",
      "\t-0.2251       = Validation score (-WQL)\n",
      "\t550.92  s     = Training runtime\n",
      "\t0.56    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosZeroShot[bolt_base]': 0.16, 'DynamicOptimizedTheta': 0.15, 'NPTS': 0.15, 'PatchTST': 0.55}\n",
      "\t-0.1730       = Validation score (-WQL)\n",
      "\t2.07    s     = Training runtime\n",
      "\t5.16    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1364.84 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1730\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_154825'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.42 GB / 15.69 GB (28.2%)\n",
      "Disk Space Avail:   152.98 GB / 459.95 GB (33.3%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 9503 rows, 812 time series. Median time series length is 12 (min=7, max=12). \n",
      "\tRemoving 35 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 9239 rows, 777 time series. Median time series length is 12 (min=9, max=12). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['cat_delta_tn_lag_12', 'cat_delta_tn_lag_13', 'cat_season_yearly', 'cat_total_tn_lag_12', 'cat_total_tn_lag_13', 'cat_trend', 'delta_tn_12', 'delta_tn_13', 'delta_tn_14', 'delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'otros_avg_lag12', 'otros_avg_lag13', 'otros_total_tn_lag12', 'otros_total_tn_lag13', 'outlier-2', 'prod_season_yearly', 'prod_trend', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'share_producto_en_categoria_lag_12', 'share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_12', 'tasa_crecimiento_share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_12', 'tn_lag_13', 'tn_lag_14', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn', 'total_season_yearly', 'total_total_tn_diff_12', 'total_total_tn_diff_13', 'total_total_tn_lag_12', 'total_total_tn_lag_13', 'total_trend']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 12:48:28\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.2564       = Validation score (-WQL)\n",
      "\t0.55    s     = Training runtime\n",
      "\t0.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2729       = Validation score (-WQL)\n",
      "\t2.48    s     = Training runtime\n",
      "\t0.12    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.9s of remaining time.\n",
      "\t-0.2425       = Validation score (-WQL)\n",
      "\t61.72   s     = Training runtime\n",
      "\t0.26    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 353.4s of the 3533.8s of remaining time.\n",
      "\t-0.3227       = Validation score (-WQL)\n",
      "\t0.69    s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 392.5s of the 3532.5s of remaining time.\n",
      "\t-0.2316       = Validation score (-WQL)\n",
      "\t0.78    s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 441.4s of the 3531.1s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 30 time series (3.9%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2217       = Validation score (-WQL)\n",
      "\t0.97    s     = Training runtime\n",
      "\t0.48    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 504.2s of the 3529.7s of remaining time.\n",
      "\t-0.2277       = Validation score (-WQL)\n",
      "\t4.59    s     = Training runtime\n",
      "\t4.30    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 586.8s of the 3520.7s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_154825\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_154825\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2129       = Validation score (-WQL)\n",
      "\t519.68  s     = Training runtime\n",
      "\t0.59    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 600.1s of the 3000.5s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 796.6s of the 2989.7s of remaining time.\n",
      "\t-0.2260       = Validation score (-WQL)\n",
      "\t152.67  s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1118.2s of the 2836.4s of remaining time.\n",
      "\t-0.1983       = Validation score (-WQL)\n",
      "\t94.89   s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2141.3s of the 2741.3s of remaining time.\n",
      "\t-0.2517       = Validation score (-WQL)\n",
      "\t397.76  s     = Training runtime\n",
      "\t0.51    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.06, 'ChronosZeroShot[bolt_base]': 0.22, 'DynamicOptimizedTheta': 0.01, 'PatchTST': 0.71}\n",
      "\t-0.1934       = Validation score (-WQL)\n",
      "\t2.38    s     = Training runtime\n",
      "\t5.68    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1259.42 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1934\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_160942'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.54 GB / 15.69 GB (29.0%)\n",
      "Disk Space Avail:   152.56 GB / 459.95 GB (33.2%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 10440 rows, 835 time series. Median time series length is 13 (min=7, max=13). \n",
      "\tRemoving 47 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 10092 rows, 788 time series. Median time series length is 13 (min=9, max=13). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['cat_delta_tn_lag_13', 'cat_total_tn_lag_13', 'delta_tn_13', 'delta_tn_14', 'delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'otros_avg_lag13', 'otros_total_tn_lag13', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_13', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_13', 'tn_lag_14', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn', 'total_total_tn_diff_13', 'total_total_tn_lag_13']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 13:09:45\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.8s of remaining time.\n",
      "\t-0.2618       = Validation score (-WQL)\n",
      "\t0.49    s     = Training runtime\n",
      "\t0.62    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.6s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.3191       = Validation score (-WQL)\n",
      "\t2.05    s     = Training runtime\n",
      "\t0.11    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.4s of remaining time.\n",
      "\t-0.2451       = Validation score (-WQL)\n",
      "\t12.33   s     = Training runtime\n",
      "\t0.19    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 358.4s of the 3583.9s of remaining time.\n",
      "\t-0.2872       = Validation score (-WQL)\n",
      "\t0.61    s     = Training runtime\n",
      "\t0.50    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 398.1s of the 3582.8s of remaining time.\n",
      "\t-0.2564       = Validation score (-WQL)\n",
      "\t0.70    s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 447.7s of the 3581.5s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 33 time series (4.2%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2503       = Validation score (-WQL)\n",
      "\t0.90    s     = Training runtime\n",
      "\t0.48    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 511.4s of the 3580.1s of remaining time.\n",
      "\t-0.2404       = Validation score (-WQL)\n",
      "\t4.40    s     = Training runtime\n",
      "\t4.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 595.2s of the 3571.5s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_160942\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_160942\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2405       = Validation score (-WQL)\n",
      "\t527.38  s     = Training runtime\n",
      "\t0.72    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 610.8s of the 3043.3s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 810.5s of the 3031.5s of remaining time.\n",
      "\t-0.2428       = Validation score (-WQL)\n",
      "\t208.39  s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1111.3s of the 2822.5s of remaining time.\n",
      "\t-0.1984       = Validation score (-WQL)\n",
      "\t89.46   s     = Training runtime\n",
      "\t0.25    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2132.8s of the 2732.8s of remaining time.\n",
      "\t-0.2258       = Validation score (-WQL)\n",
      "\t322.75  s     = Training runtime\n",
      "\t0.48    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosZeroShot[bolt_base]': 0.01, 'NPTS': 0.23, 'PatchTST': 0.76}\n",
      "\t-0.1919       = Validation score (-WQL)\n",
      "\t2.13    s     = Training runtime\n",
      "\t4.98    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1192.72 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1919\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_162949'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.85 GB / 15.69 GB (30.9%)\n",
      "Disk Space Avail:   152.19 GB / 459.95 GB (33.1%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 11264 rows, 840 time series. Median time series length is 14 (min=7, max=14). \n",
      "\tRemoving 41 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 10946 rows, 799 time series. Median time series length is 14 (min=9, max=14). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_14', 'delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_14', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 13:29:53\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.2711       = Validation score (-WQL)\n",
      "\t0.53    s     = Training runtime\n",
      "\t0.44    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.8s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2973       = Validation score (-WQL)\n",
      "\t2.34    s     = Training runtime\n",
      "\t0.12    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.3s of remaining time.\n",
      "\t-0.1975       = Validation score (-WQL)\n",
      "\t48.85   s     = Training runtime\n",
      "\t0.97    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 354.6s of the 3546.4s of remaining time.\n",
      "\t-0.3438       = Validation score (-WQL)\n",
      "\t0.67    s     = Training runtime\n",
      "\t0.53    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 393.9s of the 3545.2s of remaining time.\n",
      "\t-0.2637       = Validation score (-WQL)\n",
      "\t2.60    s     = Training runtime\n",
      "\t0.61    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 442.7s of the 3542.0s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 38 time series (4.8%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2466       = Validation score (-WQL)\n",
      "\t0.95    s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 505.8s of the 3540.5s of remaining time.\n",
      "\t-0.2426       = Validation score (-WQL)\n",
      "\t4.75    s     = Training runtime\n",
      "\t4.50    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 588.5s of the 3531.2s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_162949\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_162949\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2098       = Validation score (-WQL)\n",
      "\t521.29  s     = Training runtime\n",
      "\t0.66    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 602.3s of the 3009.2s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 799.2s of the 2997.6s of remaining time.\n",
      "\t-0.2478       = Validation score (-WQL)\n",
      "\t183.72  s     = Training runtime\n",
      "\t0.57    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1106.6s of the 2813.3s of remaining time.\n",
      "\t-0.1925       = Validation score (-WQL)\n",
      "\t116.12  s     = Training runtime\n",
      "\t0.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2096.9s of the 2696.9s of remaining time.\n",
      "\t-0.2300       = Validation score (-WQL)\n",
      "\t287.91  s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.01, 'ChronosZeroShot[bolt_base]': 0.11, 'DirectTabular': 0.23, 'NPTS': 0.1, 'PatchTST': 0.54}\n",
      "\t-0.1791       = Validation score (-WQL)\n",
      "\t1.97    s     = Training runtime\n",
      "\t6.88    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1193.63 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1791\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_165001'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.84 GB / 15.69 GB (30.9%)\n",
      "Disk Space Avail:   151.75 GB / 459.95 GB (33.0%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 12101 rows, 847 time series. Median time series length is 15 (min=7, max=15). \n",
      "\tRemoving 25 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 11913 rows, 822 time series. Median time series length is 15 (min=9, max=15). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_15', 'delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_15', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 13:50:05\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3060       = Validation score (-WQL)\n",
      "\t0.58    s     = Training runtime\n",
      "\t0.42    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.7s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.3335       = Validation score (-WQL)\n",
      "\t2.12    s     = Training runtime\n",
      "\t0.11    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.4s of remaining time.\n",
      "\t-0.2508       = Validation score (-WQL)\n",
      "\t46.39   s     = Training runtime\n",
      "\t1.01    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 354.9s of the 3549.0s of remaining time.\n",
      "\t-0.3083       = Validation score (-WQL)\n",
      "\t0.68    s     = Training runtime\n",
      "\t0.55    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 394.2s of the 3547.8s of remaining time.\n",
      "\t-0.2869       = Validation score (-WQL)\n",
      "\t2.56    s     = Training runtime\n",
      "\t0.61    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 443.1s of the 3544.6s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 54 time series (6.6%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2675       = Validation score (-WQL)\n",
      "\t0.92    s     = Training runtime\n",
      "\t0.57    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 506.2s of the 3543.1s of remaining time.\n",
      "\t-0.2688       = Validation score (-WQL)\n",
      "\t4.89    s     = Training runtime\n",
      "\t4.35    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 589.0s of the 3533.8s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_165001\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_165001\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2469       = Validation score (-WQL)\n",
      "\t521.69  s     = Training runtime\n",
      "\t0.74    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 602.8s of the 3011.4s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 799.4s of the 2998.1s of remaining time.\n",
      "\t-0.2774       = Validation score (-WQL)\n",
      "\t227.34  s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1085.1s of the 2770.1s of remaining time.\n",
      "\t-0.2141       = Validation score (-WQL)\n",
      "\t66.54   s     = Training runtime\n",
      "\t0.32    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2103.2s of the 2703.2s of remaining time.\n",
      "\t-0.2526       = Validation score (-WQL)\n",
      "\t353.82  s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'NPTS': 0.32, 'PatchTST': 0.59, 'TiDE': 0.1}\n",
      "\t-0.1966       = Validation score (-WQL)\n",
      "\t2.06    s     = Training runtime\n",
      "\t1.39    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1253.23 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1966\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_171107'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.68 GB / 15.69 GB (29.9%)\n",
      "Disk Space Avail:   151.31 GB / 459.95 GB (32.9%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 13069 rows, 873 time series. Median time series length is 16 (min=7, max=16). \n",
      "\tRemoving 46 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 12732 rows, 827 time series. Median time series length is 16 (min=9, max=16). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_16', 'delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_16', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 14:11:10\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.2463       = Validation score (-WQL)\n",
      "\t0.60    s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.4s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2809       = Validation score (-WQL)\n",
      "\t2.19    s     = Training runtime\n",
      "\t0.12    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.1s of remaining time.\n",
      "\t-0.2300       = Validation score (-WQL)\n",
      "\t56.58   s     = Training runtime\n",
      "\t0.25    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 353.9s of the 3539.2s of remaining time.\n",
      "\t-0.3087       = Validation score (-WQL)\n",
      "\t0.74    s     = Training runtime\n",
      "\t0.59    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 393.1s of the 3537.9s of remaining time.\n",
      "\t-0.2593       = Validation score (-WQL)\n",
      "\t2.65    s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 441.8s of the 3534.6s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 48 time series (5.8%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2485       = Validation score (-WQL)\n",
      "\t1.14    s     = Training runtime\n",
      "\t0.55    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 504.7s of the 3532.8s of remaining time.\n",
      "\t-0.2459       = Validation score (-WQL)\n",
      "\t4.88    s     = Training runtime\n",
      "\t4.35    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 587.3s of the 3523.6s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_171107\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_171107\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2389       = Validation score (-WQL)\n",
      "\t520.39  s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 600.6s of the 3002.5s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 796.8s of the 2990.3s of remaining time.\n",
      "\t-0.2349       = Validation score (-WQL)\n",
      "\t225.62  s     = Training runtime\n",
      "\t1.08    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1081.8s of the 2763.5s of remaining time.\n",
      "\t-0.2097       = Validation score (-WQL)\n",
      "\t121.09  s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2041.7s of the 2641.7s of remaining time.\n",
      "\t-0.2023       = Validation score (-WQL)\n",
      "\t529.67  s     = Training runtime\n",
      "\t0.48    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'NPTS': 0.23, 'PatchTST': 0.16, 'SeasonalNaive': 0.09, 'TiDE': 0.52}\n",
      "\t-0.1935       = Validation score (-WQL)\n",
      "\t2.13    s     = Training runtime\n",
      "\t2.41    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1490.64 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1935\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_173609'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       3.33 GB / 15.69 GB (21.2%)\n",
      "Disk Space Avail:   150.99 GB / 459.95 GB (32.8%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 14014 rows, 893 time series. Median time series length is 17 (min=7, max=17). \n",
      "\tRemoving 59 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 13568 rows, 834 time series. Median time series length is 17 (min=9, max=17). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_17', 'delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_17', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 14:36:13\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.8s of remaining time.\n",
      "\t-0.2750       = Validation score (-WQL)\n",
      "\t0.63    s     = Training runtime\n",
      "\t0.64    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2468       = Validation score (-WQL)\n",
      "\t2.47    s     = Training runtime\n",
      "\t0.12    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.9s of remaining time.\n",
      "\t-0.2201       = Validation score (-WQL)\n",
      "\t45.70   s     = Training runtime\n",
      "\t0.18    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 355.0s of the 3550.0s of remaining time.\n",
      "\t-0.3039       = Validation score (-WQL)\n",
      "\t0.69    s     = Training runtime\n",
      "\t0.73    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 394.3s of the 3548.6s of remaining time.\n",
      "\t-0.2251       = Validation score (-WQL)\n",
      "\t3.91    s     = Training runtime\n",
      "\t0.80    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 443.0s of the 3543.8s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 32 time series (3.8%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2124       = Validation score (-WQL)\n",
      "\t1.68    s     = Training runtime\n",
      "\t0.80    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 505.9s of the 3541.3s of remaining time.\n",
      "\t-0.2213       = Validation score (-WQL)\n",
      "\t5.89    s     = Training runtime\n",
      "\t4.93    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 588.4s of the 3530.5s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_173609\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_173609\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2059       = Validation score (-WQL)\n",
      "\t522.03  s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 602.0s of the 3007.8s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 799.4s of the 2998.2s of remaining time.\n",
      "\t-0.2497       = Validation score (-WQL)\n",
      "\t89.26   s     = Training runtime\n",
      "\t0.50    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1154.2s of the 2908.4s of remaining time.\n",
      "\t-0.1981       = Validation score (-WQL)\n",
      "\t50.35   s     = Training runtime\n",
      "\t0.18    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2257.9s of the 2857.9s of remaining time.\n",
      "\t-0.2126       = Validation score (-WQL)\n",
      "\t370.38  s     = Training runtime\n",
      "\t0.50    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.09, 'ChronosZeroShot[bolt_base]': 0.06, 'NPTS': 0.18, 'PatchTST': 0.41, 'TiDE': 0.25}\n",
      "\t-0.1825       = Validation score (-WQL)\n",
      "\t1.99    s     = Training runtime\n",
      "\t7.14    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1115.12 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1825\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_175504'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.95 GB / 15.69 GB (12.4%)\n",
      "Disk Space Avail:   150.54 GB / 459.95 GB (32.7%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 14826 rows, 893 time series. Median time series length is 18 (min=7, max=18). \n",
      "\tRemoving 35 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 14552 rows, 858 time series. Median time series length is 18 (min=9, max=18). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_18', 'delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_18', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 14:55:08\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.8s of remaining time.\n",
      "\t-0.2656       = Validation score (-WQL)\n",
      "\t0.59    s     = Training runtime\n",
      "\t0.66    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2413       = Validation score (-WQL)\n",
      "\t2.56    s     = Training runtime\n",
      "\t0.13    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.8s of remaining time.\n",
      "\t-0.2413       = Validation score (-WQL)\n",
      "\t15.17   s     = Training runtime\n",
      "\t0.19    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 358.0s of the 3580.4s of remaining time.\n",
      "\t-0.3320       = Validation score (-WQL)\n",
      "\t0.69    s     = Training runtime\n",
      "\t0.64    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.7s of the 3579.1s of remaining time.\n",
      "\t-0.2136       = Validation score (-WQL)\n",
      "\t0.89    s     = Training runtime\n",
      "\t0.68    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 447.2s of the 3577.5s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 51 time series (5.9%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2146       = Validation score (-WQL)\n",
      "\t0.96    s     = Training runtime\n",
      "\t0.61    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 510.8s of the 3575.9s of remaining time.\n",
      "\t-0.2196       = Validation score (-WQL)\n",
      "\t4.49    s     = Training runtime\n",
      "\t4.13    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 594.5s of the 3567.3s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_175504\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_175504\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2218       = Validation score (-WQL)\n",
      "\t526.44  s     = Training runtime\n",
      "\t0.66    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 610.0s of the 3040.2s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 810.2s of the 3030.6s of remaining time.\n",
      "\t-0.2261       = Validation score (-WQL)\n",
      "\t175.91  s     = Training runtime\n",
      "\t0.74    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1127.0s of the 2853.9s of remaining time.\n",
      "\t-0.1949       = Validation score (-WQL)\n",
      "\t123.58  s     = Training runtime\n",
      "\t0.41    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2129.9s of the 2729.9s of remaining time.\n",
      "\t-0.2557       = Validation score (-WQL)\n",
      "\t442.03  s     = Training runtime\n",
      "\t0.51    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.05, 'DynamicOptimizedTheta': 0.11, 'NPTS': 0.02, 'PatchTST': 0.69, 'RecursiveTabular': 0.04, 'SeasonalNaive': 0.09}\n",
      "\t-0.1919       = Validation score (-WQL)\n",
      "\t2.05    s     = Training runtime\n",
      "\t3.13    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1314.80 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1919\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_181716'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       5.16 GB / 15.69 GB (32.9%)\n",
      "Disk Space Avail:   150.31 GB / 459.95 GB (32.7%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 15666 rows, 898 time series. Median time series length is 19 (min=7, max=19). \n",
      "\tRemoving 20 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 15517 rows, 878 time series. Median time series length is 19 (min=9, max=19). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_19', 'delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_19', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 15:17:20\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.8s of remaining time.\n",
      "\t-0.2818       = Validation score (-WQL)\n",
      "\t0.68    s     = Training runtime\n",
      "\t0.43    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.7s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2925       = Validation score (-WQL)\n",
      "\t2.52    s     = Training runtime\n",
      "\t0.13    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.0s of remaining time.\n",
      "\t-0.2138       = Validation score (-WQL)\n",
      "\t33.98   s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 356.1s of the 3561.3s of remaining time.\n",
      "\t-0.3552       = Validation score (-WQL)\n",
      "\t0.75    s     = Training runtime\n",
      "\t0.57    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 395.6s of the 3560.0s of remaining time.\n",
      "\t-0.2162       = Validation score (-WQL)\n",
      "\t0.85    s     = Training runtime\n",
      "\t0.70    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 444.8s of the 3558.4s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 64 time series (7.3%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2132       = Validation score (-WQL)\n",
      "\t0.93    s     = Training runtime\n",
      "\t0.56    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 508.1s of the 3556.9s of remaining time.\n",
      "\t-0.2107       = Validation score (-WQL)\n",
      "\t4.98    s     = Training runtime\n",
      "\t4.86    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 591.2s of the 3547.0s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_181716\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_181716\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2075       = Validation score (-WQL)\n",
      "\t523.79  s     = Training runtime\n",
      "\t0.86    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 605.6s of the 3022.3s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 803.5s of the 3010.4s of remaining time.\n",
      "\t-0.2392       = Validation score (-WQL)\n",
      "\t143.49  s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1133.1s of the 2866.2s of remaining time.\n",
      "\t-0.1917       = Validation score (-WQL)\n",
      "\t106.24  s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2159.7s of the 2759.7s of remaining time.\n",
      "\t-0.1984       = Validation score (-WQL)\n",
      "\t299.12  s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.05, 'ChronosZeroShot[bolt_base]': 0.15, 'DeepAR': 0.05, 'DynamicOptimizedTheta': 0.14, 'NPTS': 0.07, 'PatchTST': 0.01, 'TiDE': 0.53}\n",
      "\t-0.1804       = Validation score (-WQL)\n",
      "\t2.02    s     = Training runtime\n",
      "\t8.07    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1142.15 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1804\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_183641'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       5.10 GB / 15.69 GB (32.5%)\n",
      "Disk Space Avail:   149.91 GB / 459.95 GB (32.6%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 16501 rows, 902 time series. Median time series length is 20 (min=7, max=20). \n",
      "\tRemoving 24 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 16319 rows, 878 time series. Median time series length is 20 (min=9, max=20). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_20', 'delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_20', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 15:36:46\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.2715       = Validation score (-WQL)\n",
      "\t0.62    s     = Training runtime\n",
      "\t0.48    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.6s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2185       = Validation score (-WQL)\n",
      "\t2.84    s     = Training runtime\n",
      "\t0.14    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.6s of remaining time.\n",
      "\t-0.2194       = Validation score (-WQL)\n",
      "\t19.50   s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.6s of the 3575.9s of remaining time.\n",
      "\t-0.3462       = Validation score (-WQL)\n",
      "\t0.70    s     = Training runtime\n",
      "\t0.55    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.2s of the 3574.6s of remaining time.\n",
      "\t-0.2045       = Validation score (-WQL)\n",
      "\t0.89    s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 446.6s of the 3573.1s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 41 time series (4.7%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2121       = Validation score (-WQL)\n",
      "\t0.99    s     = Training runtime\n",
      "\t0.56    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 510.2s of the 3571.5s of remaining time.\n",
      "\t-0.1950       = Validation score (-WQL)\n",
      "\t4.61    s     = Training runtime\n",
      "\t4.82    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 593.7s of the 3562.1s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_183641\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_183641\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.1965       = Validation score (-WQL)\n",
      "\t525.74  s     = Training runtime\n",
      "\t0.91    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 608.8s of the 3035.4s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 807.9s of the 3023.7s of remaining time.\n",
      "\t-0.2036       = Validation score (-WQL)\n",
      "\t181.14  s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1121.0s of the 2842.0s of remaining time.\n",
      "\t-0.1871       = Validation score (-WQL)\n",
      "\t98.42   s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2143.3s of the 2743.3s of remaining time.\n",
      "\t-0.2138       = Validation score (-WQL)\n",
      "\t392.70  s     = Training runtime\n",
      "\t0.56    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosZeroShot[bolt_base]': 0.11, 'NPTS': 0.05, 'PatchTST': 0.52, 'RecursiveTabular': 0.2, 'TiDE': 0.11}\n",
      "\t-0.1780       = Validation score (-WQL)\n",
      "\t2.12    s     = Training runtime\n",
      "\t6.27    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1252.21 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1780\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_185753'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       5.11 GB / 15.69 GB (32.6%)\n",
      "Disk Space Avail:   149.51 GB / 459.95 GB (32.5%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 17371 rows, 911 time series. Median time series length is 21 (min=7, max=21). \n",
      "\tRemoving 28 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 17162 rows, 883 time series. Median time series length is 21 (min=9, max=21). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_21', 'delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_21', 'tn_lag_22', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 15:57:58\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.8s of remaining time.\n",
      "\t-0.3203       = Validation score (-WQL)\n",
      "\t0.61    s     = Training runtime\n",
      "\t0.49    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.7s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.3130       = Validation score (-WQL)\n",
      "\t2.52    s     = Training runtime\n",
      "\t0.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.0s of remaining time.\n",
      "\t-0.2216       = Validation score (-WQL)\n",
      "\t13.59   s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 358.2s of the 3582.2s of remaining time.\n",
      "\t-0.4042       = Validation score (-WQL)\n",
      "\t0.71    s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.9s of the 3580.8s of remaining time.\n",
      "\t-0.2263       = Validation score (-WQL)\n",
      "\t2.69    s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 447.2s of the 3577.5s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 26 time series (2.9%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2339       = Validation score (-WQL)\n",
      "\t1.05    s     = Training runtime\n",
      "\t0.68    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 510.8s of the 3575.7s of remaining time.\n",
      "\t-0.2088       = Validation score (-WQL)\n",
      "\t5.08    s     = Training runtime\n",
      "\t4.93    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 594.3s of the 3565.6s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_185753\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_185753\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2072       = Validation score (-WQL)\n",
      "\t526.51  s     = Training runtime\n",
      "\t0.85    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 609.6s of the 3038.2s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 808.9s of the 3026.8s of remaining time.\n",
      "\t-0.2194       = Validation score (-WQL)\n",
      "\t138.16  s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1144.0s of the 2887.9s of remaining time.\n",
      "\t-0.1957       = Validation score (-WQL)\n",
      "\t112.54  s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2175.2s of the 2775.2s of remaining time.\n",
      "\t-0.1974       = Validation score (-WQL)\n",
      "\t412.42  s     = Training runtime\n",
      "\t0.54    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosZeroShot[bolt_base]': 0.25, 'DynamicOptimizedTheta': 0.02, 'NPTS': 0.03, 'PatchTST': 0.23, 'SeasonalNaive': 0.02, 'TiDE': 0.45}\n",
      "\t-0.1889       = Validation score (-WQL)\n",
      "\t2.23    s     = Training runtime\n",
      "\t7.39    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1240.24 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1889\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_191857'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.58 GB / 15.69 GB (29.2%)\n",
      "Disk Space Avail:   149.12 GB / 459.95 GB (32.4%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 18284 rows, 925 time series. Median time series length is 22 (min=7, max=22). \n",
      "\tRemoving 38 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 18000 rows, 887 time series. Median time series length is 22 (min=9, max=22). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_22', 'delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_23', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 16:19:03\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.8s of remaining time.\n",
      "\t-0.3598       = Validation score (-WQL)\n",
      "\t0.62    s     = Training runtime\n",
      "\t0.64    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2422       = Validation score (-WQL)\n",
      "\t2.58    s     = Training runtime\n",
      "\t0.13    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.7s of remaining time.\n",
      "\t-0.2270       = Validation score (-WQL)\n",
      "\t21.14   s     = Training runtime\n",
      "\t0.34    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.4s of the 3574.2s of remaining time.\n",
      "\t-0.4534       = Validation score (-WQL)\n",
      "\t0.75    s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.0s of the 3572.8s of remaining time.\n",
      "\t-0.2340       = Validation score (-WQL)\n",
      "\t1.06    s     = Training runtime\n",
      "\t0.76    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 446.4s of the 3571.0s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 30 time series (3.4%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2447       = Validation score (-WQL)\n",
      "\t1.10    s     = Training runtime\n",
      "\t0.61    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.9s of the 3569.3s of remaining time.\n",
      "\t-0.2092       = Validation score (-WQL)\n",
      "\t5.67    s     = Training runtime\n",
      "\t4.88    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 593.1s of the 3558.7s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_191857\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_191857\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2111       = Validation score (-WQL)\n",
      "\t525.20  s     = Training runtime\n",
      "\t0.84    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 608.1s of the 3032.6s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 807.0s of the 3021.1s of remaining time.\n",
      "\t-0.2030       = Validation score (-WQL)\n",
      "\t173.25  s     = Training runtime\n",
      "\t0.70    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1123.5s of the 2847.1s of remaining time.\n",
      "\t-0.2006       = Validation score (-WQL)\n",
      "\t96.99   s     = Training runtime\n",
      "\t0.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2149.8s of the 2749.8s of remaining time.\n",
      "\t-0.1946       = Validation score (-WQL)\n",
      "\t453.70  s     = Training runtime\n",
      "\t0.59    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosZeroShot[bolt_base]': 0.11, 'DeepAR': 0.27, 'NPTS': 0.04, 'RecursiveTabular': 0.14, 'TiDE': 0.44}\n",
      "\t-0.1855       = Validation score (-WQL)\n",
      "\t2.19    s     = Training runtime\n",
      "\t6.92    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1306.82 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1855\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_194107'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       5.16 GB / 15.69 GB (32.9%)\n",
      "Disk Space Avail:   148.71 GB / 459.95 GB (32.3%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 19192 rows, 937 time series. Median time series length is 23 (min=7, max=23). \n",
      "\tRemoving 41 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 18882 rows, 896 time series. Median time series length is 23 (min=9, max=23). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_23', 'delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_24', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 16:41:14\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3933       = Validation score (-WQL)\n",
      "\t0.63    s     = Training runtime\n",
      "\t0.51    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2323       = Validation score (-WQL)\n",
      "\t2.83    s     = Training runtime\n",
      "\t0.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.5s of remaining time.\n",
      "\t-0.2391       = Validation score (-WQL)\n",
      "\t23.02   s     = Training runtime\n",
      "\t0.28    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.2s of the 3572.2s of remaining time.\n",
      "\t-0.5020       = Validation score (-WQL)\n",
      "\t0.93    s     = Training runtime\n",
      "\t0.62    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 396.7s of the 3570.6s of remaining time.\n",
      "\t-0.2359       = Validation score (-WQL)\n",
      "\t3.09    s     = Training runtime\n",
      "\t0.72    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 445.8s of the 3566.8s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 34 time series (3.8%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2534       = Validation score (-WQL)\n",
      "\t1.33    s     = Training runtime\n",
      "\t0.80    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.2s of the 3564.6s of remaining time.\n",
      "\t-0.2157       = Validation score (-WQL)\n",
      "\t5.27    s     = Training runtime\n",
      "\t5.00    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 592.4s of the 3554.3s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_194107\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_194107\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2077       = Validation score (-WQL)\n",
      "\t525.50  s     = Training runtime\n",
      "\t0.90    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 607.0s of the 3027.9s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 805.2s of the 3015.7s of remaining time.\n",
      "\t-0.2104       = Validation score (-WQL)\n",
      "\t307.56  s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1053.7s of the 2707.5s of remaining time.\n",
      "\t-0.2122       = Validation score (-WQL)\n",
      "\t140.37  s     = Training runtime\n",
      "\t0.32    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 1966.8s of the 2566.8s of remaining time.\n",
      "\t-0.2211       = Validation score (-WQL)\n",
      "\t304.12  s     = Training runtime\n",
      "\t0.62    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.16, 'DeepAR': 0.4, 'PatchTST': 0.16, 'RecursiveTabular': 0.24, 'SeasonalNaive': 0.03}\n",
      "\t-0.1980       = Validation score (-WQL)\n",
      "\t2.14    s     = Training runtime\n",
      "\t2.52    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1340.20 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1980\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_200346'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.79 GB / 15.69 GB (30.5%)\n",
      "Disk Space Avail:   148.31 GB / 459.95 GB (32.2%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 20029 rows, 938 time series. Median time series length is 24 (min=7, max=24). \n",
      "\tRemoving 28 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 19812 rows, 910 time series. Median time series length is 24 (min=9, max=24). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_24', 'delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_25', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 17:03:51\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.4355       = Validation score (-WQL)\n",
      "\t0.86    s     = Training runtime\n",
      "\t0.50    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.4s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2718       = Validation score (-WQL)\n",
      "\t2.45    s     = Training runtime\n",
      "\t0.16    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.7s of remaining time.\n",
      "\t-0.2374       = Validation score (-WQL)\n",
      "\t71.96   s     = Training runtime\n",
      "\t1.08    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 352.3s of the 3522.6s of remaining time.\n",
      "\t-0.5534       = Validation score (-WQL)\n",
      "\t0.92    s     = Training runtime\n",
      "\t0.61    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 391.2s of the 3521.1s of remaining time.\n",
      "\t-0.2622       = Validation score (-WQL)\n",
      "\t2.78    s     = Training runtime\n",
      "\t0.72    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 439.7s of the 3517.5s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 44 time series (4.8%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2828       = Validation score (-WQL)\n",
      "\t1.12    s     = Training runtime\n",
      "\t0.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 502.2s of the 3515.7s of remaining time.\n",
      "\t-0.2412       = Validation score (-WQL)\n",
      "\t5.63    s     = Training runtime\n",
      "\t5.10    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 584.2s of the 3505.0s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_200346\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_200346\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2203       = Validation score (-WQL)\n",
      "\t517.62  s     = Training runtime\n",
      "\t0.87    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 597.3s of the 2986.5s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 791.2s of the 2973.6s of remaining time.\n",
      "\t-0.2239       = Validation score (-WQL)\n",
      "\t295.33  s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1038.8s of the 2677.6s of remaining time.\n",
      "\t-0.2174       = Validation score (-WQL)\n",
      "\t104.79  s     = Training runtime\n",
      "\t0.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 1972.5s of the 2572.5s of remaining time.\n",
      "\t-0.2334       = Validation score (-WQL)\n",
      "\t331.27  s     = Training runtime\n",
      "\t0.69    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.1, 'DeepAR': 0.26, 'NPTS': 0.03, 'PatchTST': 0.01, 'RecursiveTabular': 0.16, 'TiDE': 0.43}\n",
      "\t-0.1991       = Validation score (-WQL)\n",
      "\t2.46    s     = Training runtime\n",
      "\t3.17    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1362.09 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1991\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_202646'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.76 GB / 15.69 GB (30.3%)\n",
      "Disk Space Avail:   147.84 GB / 459.95 GB (32.1%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 20885 rows, 942 time series. Median time series length is 25 (min=7, max=25). \n",
      "\tRemoving 20 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 20735 rows, 922 time series. Median time series length is 25 (min=9, max=25). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_25', 'delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_26', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 17:26:52\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3936       = Validation score (-WQL)\n",
      "\t0.69    s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2435       = Validation score (-WQL)\n",
      "\t2.29    s     = Training runtime\n",
      "\t0.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.1s of remaining time.\n",
      "\t-0.2363       = Validation score (-WQL)\n",
      "\t21.23   s     = Training runtime\n",
      "\t0.31    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.5s of the 3574.5s of remaining time.\n",
      "\t-0.4959       = Validation score (-WQL)\n",
      "\t0.78    s     = Training runtime\n",
      "\t0.62    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.0s of the 3573.1s of remaining time.\n",
      "\t-0.2701       = Validation score (-WQL)\n",
      "\t2.71    s     = Training runtime\n",
      "\t0.73    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 446.2s of the 3569.6s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 47 time series (5.1%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2791       = Validation score (-WQL)\n",
      "\t1.15    s     = Training runtime\n",
      "\t0.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.7s of the 3567.8s of remaining time.\n",
      "\t-0.2413       = Validation score (-WQL)\n",
      "\t5.61    s     = Training runtime\n",
      "\t4.94    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 592.9s of the 3557.2s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_202646\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_202646\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2108       = Validation score (-WQL)\n",
      "\t525.16  s     = Training runtime\n",
      "\t0.89    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 607.8s of the 3031.1s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 806.2s of the 3018.6s of remaining time.\n",
      "\t-0.2300       = Validation score (-WQL)\n",
      "\t138.24  s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1139.9s of the 2879.7s of remaining time.\n",
      "\t-0.2217       = Validation score (-WQL)\n",
      "\t112.54  s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2166.9s of the 2766.9s of remaining time.\n",
      "\t-0.2188       = Validation score (-WQL)\n",
      "\t351.18  s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.17, 'NPTS': 0.02, 'PatchTST': 0.25, 'RecursiveTabular': 0.27, 'TiDE': 0.3}\n",
      "\t-0.1993       = Validation score (-WQL)\n",
      "\t2.42    s     = Training runtime\n",
      "\t2.47    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1187.47 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1993\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_204652'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.77 GB / 15.69 GB (30.4%)\n",
      "Disk Space Avail:   147.43 GB / 459.95 GB (32.1%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 21756 rows, 948 time series. Median time series length is 26 (min=7, max=26). \n",
      "\tRemoving 25 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 21568 rows, 923 time series. Median time series length is 26 (min=9, max=26). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_26', 'delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_27', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 17:46:58\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3564       = Validation score (-WQL)\n",
      "\t0.67    s     = Training runtime\n",
      "\t0.47    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.6s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2507       = Validation score (-WQL)\n",
      "\t2.21    s     = Training runtime\n",
      "\t0.14    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.2s of remaining time.\n",
      "\t-0.2273       = Validation score (-WQL)\n",
      "\t142.18  s     = Training runtime\n",
      "\t1.50    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 345.2s of the 3452.5s of remaining time.\n",
      "\t-0.4350       = Validation score (-WQL)\n",
      "\t0.78    s     = Training runtime\n",
      "\t0.61    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 383.5s of the 3451.1s of remaining time.\n",
      "\t-0.2526       = Validation score (-WQL)\n",
      "\t2.73    s     = Training runtime\n",
      "\t0.77    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 430.9s of the 3447.5s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 34 time series (3.7%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2688       = Validation score (-WQL)\n",
      "\t1.24    s     = Training runtime\n",
      "\t3.05    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 491.9s of the 3443.2s of remaining time.\n",
      "\t-0.2299       = Validation score (-WQL)\n",
      "\t5.58    s     = Training runtime\n",
      "\t4.96    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 572.1s of the 3432.6s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_204652\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_204652\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2072       = Validation score (-WQL)\n",
      "\t506.92  s     = Training runtime\n",
      "\t0.86    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 585.0s of the 2924.9s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 770.7s of the 2912.2s of remaining time.\n",
      "\t-0.2218       = Validation score (-WQL)\n",
      "\t247.31  s     = Training runtime\n",
      "\t0.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1032.1s of the 2664.3s of remaining time.\n",
      "\t-0.2043       = Validation score (-WQL)\n",
      "\t116.87  s     = Training runtime\n",
      "\t0.24    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 1947.1s of the 2547.1s of remaining time.\n",
      "\t-0.2219       = Validation score (-WQL)\n",
      "\t314.64  s     = Training runtime\n",
      "\t0.56    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.17, 'DeepAR': 0.17, 'DirectTabular': 0.13, 'PatchTST': 0.36, 'RecursiveTabular': 0.16}\n",
      "\t-0.1963       = Validation score (-WQL)\n",
      "\t2.06    s     = Training runtime\n",
      "\t3.39    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1370.30 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1963\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_210959'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       5.44 GB / 15.69 GB (34.7%)\n",
      "Disk Space Avail:   146.87 GB / 459.95 GB (31.9%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 22773 rows, 976 time series. Median time series length is 27 (min=7, max=27). \n",
      "\tRemoving 49 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 22415 rows, 927 time series. Median time series length is 27 (min=9, max=27). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_27', 'delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_28', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 18:10:06\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3598       = Validation score (-WQL)\n",
      "\t3.85    s     = Training runtime\n",
      "\t0.54    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.6s of the 3595.3s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2430       = Validation score (-WQL)\n",
      "\t2.42    s     = Training runtime\n",
      "\t0.16    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.6s of the 3592.7s of remaining time.\n",
      "\t-0.2535       = Validation score (-WQL)\n",
      "\t74.15   s     = Training runtime\n",
      "\t0.45    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 351.8s of the 3518.1s of remaining time.\n",
      "\t-0.4167       = Validation score (-WQL)\n",
      "\t0.82    s     = Training runtime\n",
      "\t0.66    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 390.7s of the 3516.6s of remaining time.\n",
      "\t-0.2564       = Validation score (-WQL)\n",
      "\t2.92    s     = Training runtime\n",
      "\t0.76    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 439.1s of the 3512.9s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 26 time series (2.8%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2556       = Validation score (-WQL)\n",
      "\t1.28    s     = Training runtime\n",
      "\t3.28    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 501.2s of the 3508.3s of remaining time.\n",
      "\t-0.2230       = Validation score (-WQL)\n",
      "\t5.86    s     = Training runtime\n",
      "\t5.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 582.9s of the 3497.4s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_210959\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_210959\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2041       = Validation score (-WQL)\n",
      "\t516.29  s     = Training runtime\n",
      "\t0.88    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 596.0s of the 2980.2s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 789.2s of the 2967.7s of remaining time.\n",
      "\t-0.2130       = Validation score (-WQL)\n",
      "\t186.47  s     = Training runtime\n",
      "\t0.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1090.3s of the 2780.5s of remaining time.\n",
      "\t-0.2017       = Validation score (-WQL)\n",
      "\t115.55  s     = Training runtime\n",
      "\t0.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2064.7s of the 2664.7s of remaining time.\n",
      "\t-0.2254       = Validation score (-WQL)\n",
      "\t270.92  s     = Training runtime\n",
      "\t0.58    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.4, 'DeepAR': 0.12, 'DirectTabular': 0.09, 'NPTS': 0.02, 'PatchTST': 0.05, 'RecursiveTabular': 0.17, 'TiDE': 0.16}\n",
      "\t-0.1869       = Validation score (-WQL)\n",
      "\t2.14    s     = Training runtime\n",
      "\t3.61    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1209.11 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1869\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_213029'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.81 GB / 15.69 GB (30.7%)\n",
      "Disk Space Avail:   146.38 GB / 459.95 GB (31.8%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 23776 rows, 1000 time series. Median time series length is 28 (min=7, max=28). \n",
      "\tRemoving 67 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 23270 rows, 933 time series. Median time series length is 28 (min=9, max=28). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_28', 'delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_29', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 18:30:36\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3338       = Validation score (-WQL)\n",
      "\t0.66    s     = Training runtime\n",
      "\t0.51    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2352       = Validation score (-WQL)\n",
      "\t2.22    s     = Training runtime\n",
      "\t0.16    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3596.1s of remaining time.\n",
      "\t-0.2601       = Validation score (-WQL)\n",
      "\t76.61   s     = Training runtime\n",
      "\t0.31    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 351.9s of the 3519.2s of remaining time.\n",
      "\t-0.3763       = Validation score (-WQL)\n",
      "\t0.83    s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 390.8s of the 3517.6s of remaining time.\n",
      "\t-0.2226       = Validation score (-WQL)\n",
      "\t2.90    s     = Training runtime\n",
      "\t0.78    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 439.2s of the 3513.9s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 31 time series (3.3%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2291       = Validation score (-WQL)\n",
      "\t3.60    s     = Training runtime\n",
      "\t3.40    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 501.0s of the 3506.9s of remaining time.\n",
      "\t-0.2001       = Validation score (-WQL)\n",
      "\t5.63    s     = Training runtime\n",
      "\t5.04    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 582.7s of the 3496.2s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_213029\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_213029\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2042       = Validation score (-WQL)\n",
      "\t516.39  s     = Training runtime\n",
      "\t0.88    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 595.8s of the 2978.9s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 788.8s of the 2966.3s of remaining time.\n",
      "\t-0.2137       = Validation score (-WQL)\n",
      "\t192.68  s     = Training runtime\n",
      "\t0.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1086.5s of the 2772.9s of remaining time.\n",
      "\t-0.2071       = Validation score (-WQL)\n",
      "\t78.75   s     = Training runtime\n",
      "\t0.21    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2093.9s of the 2693.9s of remaining time.\n",
      "\t-0.2134       = Validation score (-WQL)\n",
      "\t248.45  s     = Training runtime\n",
      "\t0.61    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.32, 'ChronosZeroShot[bolt_base]': 0.28, 'DeepAR': 0.16, 'DirectTabular': 0.01, 'NPTS': 0.06, 'PatchTST': 0.01, 'RecursiveTabular': 0.14, 'TiDE': 0.02}\n",
      "\t-0.1895       = Validation score (-WQL)\n",
      "\t2.13    s     = Training runtime\n",
      "\t8.52    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1157.45 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1895\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_215014'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.56 GB / 15.69 GB (29.1%)\n",
      "Disk Space Avail:   145.90 GB / 459.95 GB (31.7%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 24701 rows, 1012 time series. Median time series length is 29 (min=7, max=29). \n",
      "\tRemoving 51 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 24311 rows, 961 time series. Median time series length is 29 (min=9, max=29). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_29', 'delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'outlier-2', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_30', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 18:50:21\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3577       = Validation score (-WQL)\n",
      "\t0.75    s     = Training runtime\n",
      "\t0.50    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.4s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2374       = Validation score (-WQL)\n",
      "\t2.42    s     = Training runtime\n",
      "\t0.18    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.8s of remaining time.\n",
      "\t-0.2726       = Validation score (-WQL)\n",
      "\t30.42   s     = Training runtime\n",
      "\t0.24    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 356.5s of the 3565.1s of remaining time.\n",
      "\t-0.4134       = Validation score (-WQL)\n",
      "\t0.87    s     = Training runtime\n",
      "\t0.66    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 396.0s of the 3563.6s of remaining time.\n",
      "\t-0.2236       = Validation score (-WQL)\n",
      "\t3.02    s     = Training runtime\n",
      "\t0.79    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 445.0s of the 3559.7s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 55 time series (5.7%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2309       = Validation score (-WQL)\n",
      "\t3.84    s     = Training runtime\n",
      "\t3.45    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 507.5s of the 3552.3s of remaining time.\n",
      "\t-0.2126       = Validation score (-WQL)\n",
      "\t5.38    s     = Training runtime\n",
      "\t5.10    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 590.3s of the 3541.8s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_215014\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_215014\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2187       = Validation score (-WQL)\n",
      "\t523.31  s     = Training runtime\n",
      "\t0.92    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 604.4s of the 3017.6s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 801.7s of the 3005.2s of remaining time.\n",
      "\t-0.2254       = Validation score (-WQL)\n",
      "\t211.75  s     = Training runtime\n",
      "\t0.68    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1096.4s of the 2792.8s of remaining time.\n",
      "\t-0.2156       = Validation score (-WQL)\n",
      "\t198.76  s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 1993.7s of the 2593.7s of remaining time.\n",
      "\t-0.2356       = Validation score (-WQL)\n",
      "\t286.90  s     = Training runtime\n",
      "\t0.59    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.06, 'ChronosFineTuned[bolt_small]': 0.37, 'ChronosZeroShot[bolt_base]': 0.14, 'DeepAR': 0.18, 'PatchTST': 0.01, 'RecursiveTabular': 0.17, 'TiDE': 0.07}\n",
      "\t-0.2011       = Validation score (-WQL)\n",
      "\t2.25    s     = Training runtime\n",
      "\t11.15   s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1296.20 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.2011\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_221222'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.74 GB / 15.69 GB (30.2%)\n",
      "Disk Space Avail:   145.49 GB / 459.95 GB (31.6%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 25534 rows, 1012 time series. Median time series length is 30 (min=7, max=30). \n",
      "\tRemoving 27 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 25324 rows, 985 time series. Median time series length is 30 (min=9, max=30). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_30', 'delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_31', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 19:12:31\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3626       = Validation score (-WQL)\n",
      "\t0.78    s     = Training runtime\n",
      "\t0.50    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.4s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2494       = Validation score (-WQL)\n",
      "\t2.30    s     = Training runtime\n",
      "\t0.16    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.9s of remaining time.\n",
      "\t-0.2751       = Validation score (-WQL)\n",
      "\t24.58   s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.1s of the 3571.1s of remaining time.\n",
      "\t-0.4282       = Validation score (-WQL)\n",
      "\t0.86    s     = Training runtime\n",
      "\t0.66    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 396.6s of the 3569.5s of remaining time.\n",
      "\t-0.2276       = Validation score (-WQL)\n",
      "\t1.27    s     = Training runtime\n",
      "\t0.82    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 445.9s of the 3567.4s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 73 time series (7.4%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2385       = Validation score (-WQL)\n",
      "\t3.89    s     = Training runtime\n",
      "\t3.62    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 508.5s of the 3559.8s of remaining time.\n",
      "\t-0.2221       = Validation score (-WQL)\n",
      "\t5.40    s     = Training runtime\n",
      "\t5.12    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 591.5s of the 3549.3s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_221222\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_221222\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2299       = Validation score (-WQL)\n",
      "\t524.06  s     = Training runtime\n",
      "\t0.89    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 606.1s of the 3024.3s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 803.9s of the 3011.6s of remaining time.\n",
      "\t-0.2225       = Validation score (-WQL)\n",
      "\t269.15  s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1070.9s of the 2741.8s of remaining time.\n",
      "\t-0.2259       = Validation score (-WQL)\n",
      "\t165.09  s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 1976.4s of the 2576.4s of remaining time.\n",
      "\t-0.2364       = Validation score (-WQL)\n",
      "\t393.33  s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ChronosFineTuned[bolt_small]': 0.12, 'ChronosZeroShot[bolt_base]': 0.24, 'DeepAR': 0.36, 'DynamicOptimizedTheta': 0.07, 'PatchTST': 0.05, 'RecursiveTabular': 0.14, 'TiDE': 0.03}\n",
      "\t-0.2104       = Validation score (-WQL)\n",
      "\t2.20    s     = Training runtime\n",
      "\t8.48    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1419.91 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.2104\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_223633'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.70 GB / 15.69 GB (30.0%)\n",
      "Disk Space Avail:   144.86 GB / 459.95 GB (31.5%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 26357 rows, 1012 time series. Median time series length is 31 (min=7, max=31). \n",
      "\tRemoving 15 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 26243 rows, 997 time series. Median time series length is 31 (min=9, max=31). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_31', 'delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_32', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos', 'total_min_tn']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 19:36:41\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3336       = Validation score (-WQL)\n",
      "\t0.69    s     = Training runtime\n",
      "\t0.53    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2406       = Validation score (-WQL)\n",
      "\t2.61    s     = Training runtime\n",
      "\t0.18    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.6s of remaining time.\n",
      "\t-0.2553       = Validation score (-WQL)\n",
      "\t18.44   s     = Training runtime\n",
      "\t0.32    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.7s of the 3576.9s of remaining time.\n",
      "\t-0.3980       = Validation score (-WQL)\n",
      "\t0.85    s     = Training runtime\n",
      "\t0.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.3s of the 3575.3s of remaining time.\n",
      "\t-0.2255       = Validation score (-WQL)\n",
      "\t1.23    s     = Training runtime\n",
      "\t0.76    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 446.7s of the 3573.3s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 58 time series (5.8%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2361       = Validation score (-WQL)\n",
      "\t3.67    s     = Training runtime\n",
      "\t3.52    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.4s of the 3566.1s of remaining time.\n",
      "\t-0.2243       = Validation score (-WQL)\n",
      "\t5.38    s     = Training runtime\n",
      "\t5.07    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 592.6s of the 3555.6s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_223633\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_223633\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2180       = Validation score (-WQL)\n",
      "\t525.11  s     = Training runtime\n",
      "\t0.93    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 607.4s of the 3029.5s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 805.4s of the 3016.2s of remaining time.\n",
      "\t-0.2312       = Validation score (-WQL)\n",
      "\t237.13  s     = Training runtime\n",
      "\t0.68    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1089.2s of the 2778.3s of remaining time.\n",
      "\t-0.2279       = Validation score (-WQL)\n",
      "\t143.07  s     = Training runtime\n",
      "\t0.27    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2034.9s of the 2634.9s of remaining time.\n",
      "\t-0.2502       = Validation score (-WQL)\n",
      "\t375.73  s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.01, 'ChronosFineTuned[bolt_small]': 0.38, 'ChronosZeroShot[bolt_base]': 0.07, 'DeepAR': 0.17, 'DynamicOptimizedTheta': 0.2, 'PatchTST': 0.03, 'RecursiveTabular': 0.13}\n",
      "\t-0.2124       = Validation score (-WQL)\n",
      "\t2.44    s     = Training runtime\n",
      "\t11.40   s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1344.01 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.2124\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_225931'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.82 GB / 15.69 GB (30.7%)\n",
      "Disk Space Avail:   144.44 GB / 459.95 GB (31.4%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 27192 rows, 1016 time series. Median time series length is 32 (min=7, max=32). \n",
      "\tRemoving 19 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 27050 rows, 997 time series. Median time series length is 32 (min=9, max=32). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_32', 'delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_33', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 19:59:40\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3846       = Validation score (-WQL)\n",
      "\t0.75    s     = Training runtime\n",
      "\t0.48    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2660       = Validation score (-WQL)\n",
      "\t2.60    s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.6s of remaining time.\n",
      "\t-0.2630       = Validation score (-WQL)\n",
      "\t20.43   s     = Training runtime\n",
      "\t0.35    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.5s of the 3574.8s of remaining time.\n",
      "\t-0.4715       = Validation score (-WQL)\n",
      "\t0.87    s     = Training runtime\n",
      "\t0.70    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.0s of the 3573.2s of remaining time.\n",
      "\t-0.2550       = Validation score (-WQL)\n",
      "\t1.20    s     = Training runtime\n",
      "\t0.80    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 446.4s of the 3571.2s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 34 time series (3.4%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2654       = Validation score (-WQL)\n",
      "\t3.82    s     = Training runtime\n",
      "\t3.73    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.1s of the 3563.6s of remaining time.\n",
      "\t-0.2652       = Validation score (-WQL)\n",
      "\t5.49    s     = Training runtime\n",
      "\t5.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 592.1s of the 3552.9s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_225931\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_225931\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2441       = Validation score (-WQL)\n",
      "\t524.63  s     = Training runtime\n",
      "\t0.91    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 606.8s of the 3027.3s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 804.7s of the 3014.0s of remaining time.\n",
      "\t-0.2438       = Validation score (-WQL)\n",
      "\t176.36  s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1118.5s of the 2837.0s of remaining time.\n",
      "\t-0.2340       = Validation score (-WQL)\n",
      "\t108.93  s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2127.8s of the 2727.8s of remaining time.\n",
      "\t-0.2405       = Validation score (-WQL)\n",
      "\t555.32  s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.07, 'ChronosFineTuned[bolt_small]': 0.03, 'DynamicOptimizedTheta': 0.05, 'PatchTST': 0.52, 'RecursiveTabular': 0.07, 'TiDE': 0.26}\n",
      "\t-0.2294       = Validation score (-WQL)\n",
      "\t2.47    s     = Training runtime\n",
      "\t6.47    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1430.77 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.2294\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_232352'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.90 GB / 15.69 GB (31.2%)\n",
      "Disk Space Avail:   144.01 GB / 459.95 GB (31.3%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 28103 rows, 1032 time series. Median time series length is 33 (min=7, max=33). \n",
      "\tRemoving 35 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 27845 rows, 997 time series. Median time series length is 33 (min=9, max=33). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_33', 'delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_34', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 20:24:00\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3613       = Validation score (-WQL)\n",
      "\t1.07    s     = Training runtime\n",
      "\t0.51    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.8s of the 3598.1s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2644       = Validation score (-WQL)\n",
      "\t3.03    s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.8s of the 3594.8s of remaining time.\n",
      "\t-0.2655       = Validation score (-WQL)\n",
      "\t33.16   s     = Training runtime\n",
      "\t0.31    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 356.1s of the 3561.3s of remaining time.\n",
      "\t-0.4447       = Validation score (-WQL)\n",
      "\t1.03    s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 395.5s of the 3559.6s of remaining time.\n",
      "\t-0.2527       = Validation score (-WQL)\n",
      "\t1.31    s     = Training runtime\n",
      "\t1.07    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 444.6s of the 3557.2s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 22 time series (2.2%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2542       = Validation score (-WQL)\n",
      "\t4.17    s     = Training runtime\n",
      "\t3.90    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 507.0s of the 3549.1s of remaining time.\n",
      "\t-0.2464       = Validation score (-WQL)\n",
      "\t5.83    s     = Training runtime\n",
      "\t5.07    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 589.7s of the 3538.2s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_232352\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_232352\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2329       = Validation score (-WQL)\n",
      "\t522.56  s     = Training runtime\n",
      "\t0.92    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 603.7s of the 3014.7s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 800.3s of the 3001.0s of remaining time.\n",
      "\t-0.2417       = Validation score (-WQL)\n",
      "\t309.01  s     = Training runtime\n",
      "\t0.70    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1045.6s of the 2691.2s of remaining time.\n",
      "\t-0.2251       = Validation score (-WQL)\n",
      "\t232.71  s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 1858.2s of the 2458.2s of remaining time.\n",
      "\t-0.2385       = Validation score (-WQL)\n",
      "\t251.63  s     = Training runtime\n",
      "\t0.60    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.11, 'ChronosFineTuned[bolt_small]': 0.01, 'ChronosZeroShot[bolt_base]': 0.09, 'DeepAR': 0.02, 'PatchTST': 0.7, 'RecursiveTabular': 0.02, 'TiDE': 0.04}\n",
      "\t-0.2227       = Validation score (-WQL)\n",
      "\t2.37    s     = Training runtime\n",
      "\t11.62   s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1396.54 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.2227\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_234742'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.65 GB / 15.69 GB (29.6%)\n",
      "Disk Space Avail:   143.58 GB / 459.95 GB (31.2%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 29139 rows, 1066 time series. Median time series length is 34 (min=7, max=34). \n",
      "\tRemoving 65 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 28659 rows, 1001 time series. Median time series length is 34 (min=9, max=34). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_34', 'delta_tn_35', 'delta_tn_36', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_35', 'tn_lag_36', 'total_clientes_distintos']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 20:47:51\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3440       = Validation score (-WQL)\n",
      "\t0.74    s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.3s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2723       = Validation score (-WQL)\n",
      "\t2.79    s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.8s of the 3595.3s of remaining time.\n",
      "\t-0.2886       = Validation score (-WQL)\n",
      "\t23.40   s     = Training runtime\n",
      "\t0.33    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.1s of the 3571.5s of remaining time.\n",
      "\t-0.4226       = Validation score (-WQL)\n",
      "\t0.96    s     = Training runtime\n",
      "\t0.67    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 396.6s of the 3569.8s of remaining time.\n",
      "\t-0.2523       = Validation score (-WQL)\n",
      "\t1.28    s     = Training runtime\n",
      "\t0.82    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 446.0s of the 3567.7s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 26 time series (2.6%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2584       = Validation score (-WQL)\n",
      "\t4.37    s     = Training runtime\n",
      "\t3.94    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 508.5s of the 3559.4s of remaining time.\n",
      "\t-0.2532       = Validation score (-WQL)\n",
      "\t5.49    s     = Training runtime\n",
      "\t5.13    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 591.4s of the 3548.7s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_234742\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250713_234742\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2442       = Validation score (-WQL)\n",
      "\t524.07  s     = Training runtime\n",
      "\t0.89    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 605.9s of the 3023.7s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 803.4s of the 3010.2s of remaining time.\n",
      "\t-0.2331       = Validation score (-WQL)\n",
      "\t205.02  s     = Training runtime\n",
      "\t0.71    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1102.2s of the 2804.4s of remaining time.\n",
      "\t-0.2405       = Validation score (-WQL)\n",
      "\t192.71  s     = Training runtime\n",
      "\t0.47    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2011.2s of the 2611.2s of remaining time.\n",
      "\t-0.2800       = Validation score (-WQL)\n",
      "\t278.45  s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.12, 'ChronosFineTuned[bolt_small]': 0.02, 'ChronosZeroShot[bolt_base]': 0.05, 'DeepAR': 0.43, 'DynamicOptimizedTheta': 0.07, 'PatchTST': 0.31}\n",
      "\t-0.2270       = Validation score (-WQL)\n",
      "\t2.59    s     = Training runtime\n",
      "\t11.97   s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1270.68 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.2270\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250714_000930'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.75 GB / 15.69 GB (30.3%)\n",
      "Disk Space Avail:   143.16 GB / 459.95 GB (31.1%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 30057 rows, 1080 time series. Median time series length is 35 (min=7, max=35). \n",
      "\tRemoving 64 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 29565 rows, 1016 time series. Median time series length is 35 (min=9, max=35). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_35', 'delta_tn_36', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'tn_lag_36', 'total_clientes_distintos']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 21:09:39\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3507       = Validation score (-WQL)\n",
      "\t0.84    s     = Training runtime\n",
      "\t0.76    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.8s of the 3598.0s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2589       = Validation score (-WQL)\n",
      "\t3.14    s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.8s of the 3594.6s of remaining time.\n",
      "\t-0.2821       = Validation score (-WQL)\n",
      "\t13.56   s     = Training runtime\n",
      "\t0.30    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 358.1s of the 3580.7s of remaining time.\n",
      "\t-0.4357       = Validation score (-WQL)\n",
      "\t1.02    s     = Training runtime\n",
      "\t0.72    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.7s of the 3579.0s of remaining time.\n",
      "\t-0.2473       = Validation score (-WQL)\n",
      "\t1.46    s     = Training runtime\n",
      "\t0.90    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 447.1s of the 3576.6s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 41 time series (4.0%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2461       = Validation score (-WQL)\n",
      "\t4.15    s     = Training runtime\n",
      "\t3.98    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.8s of the 3568.4s of remaining time.\n",
      "\t-0.2440       = Validation score (-WQL)\n",
      "\t6.21    s     = Training runtime\n",
      "\t6.75    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 592.6s of the 3555.4s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250714_000930\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250714_000930\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2430       = Validation score (-WQL)\n",
      "\t525.16  s     = Training runtime\n",
      "\t1.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 607.3s of the 3029.2s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 805.1s of the 3015.2s of remaining time.\n",
      "\t-0.2508       = Validation score (-WQL)\n",
      "\t288.81  s     = Training runtime\n",
      "\t0.72    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1062.8s of the 2725.7s of remaining time.\n",
      "\t-0.2416       = Validation score (-WQL)\n",
      "\t171.15  s     = Training runtime\n",
      "\t0.25    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 1954.2s of the 2554.2s of remaining time.\n",
      "\t-0.2446       = Validation score (-WQL)\n",
      "\t474.36  s     = Training runtime\n",
      "\t0.62    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.19, 'ChronosFineTuned[bolt_small]': 0.08, 'ChronosZeroShot[bolt_base]': 0.19, 'DeepAR': 0.03, 'PatchTST': 0.01, 'RecursiveTabular': 0.08, 'TiDE': 0.4}\n",
      "\t-0.2257       = Validation score (-WQL)\n",
      "\t2.40    s     = Training runtime\n",
      "\t13.55   s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1523.37 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.2257\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250714_003531'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.22\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       5.44 GB / 15.69 GB (34.7%)\n",
      "Disk Space Avail:   142.76 GB / 459.95 GB (31.0%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'producto_total_tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 31021 rows, 1101 time series. Median time series length is 36 (min=7, max=36). \n",
      "\tRemoving 52 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 30632 rows, 1049 time series. Median time series length is 36 (min=9, max=36). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'producto_total_tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['cat1', 'cat2', 'cat3', 'brand', 'categoria', 'estado_producto']\n",
      "\t\tcontinuous (float): ['periodo', 'product_id', 'avg_tn', 'std_tn', 'clientes_distintos', 'cust_request_qty', ...]\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['delta_tn_36', 'producto_avg_tn', 'producto_clientes_distintos', 'producto_min_tn', 'producto_std_tn', 'producto_tn_media_movil_3(con_mes_en_curso)', 'tasa_crecimiento_share_producto_en_categoria_lag_1', 'tasa_crecimiento_share_producto_en_categoria_lag_2', 'tasa_crecimiento_share_producto_en_categoria_lag_3', 'tasa_crecimiento_share_producto_en_categoria_lag_4', 'tasa_crecimiento_share_producto_en_categoria_lag_5', 'tasa_crecimiento_share_producto_en_categoria_lag_6', 'tasa_crecimiento_share_producto_en_categoria_lag_7', 'tasa_crecimiento_share_producto_en_categoria_lag_8', 'total_clientes_distintos']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-13 21:35:40\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.9s of the 3599.7s of remaining time.\n",
      "\t-0.3215       = Validation score (-WQL)\n",
      "\t0.74    s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.9s of the 3598.4s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2717       = Validation score (-WQL)\n",
      "\t2.75    s     = Training runtime\n",
      "\t0.19    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.9s of the 3595.4s of remaining time.\n",
      "\t-0.3010       = Validation score (-WQL)\n",
      "\t14.43   s     = Training runtime\n",
      "\t0.28    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 358.1s of the 3580.7s of remaining time.\n",
      "\t-0.3976       = Validation score (-WQL)\n",
      "\t0.98    s     = Training runtime\n",
      "\t0.70    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.7s of the 3579.0s of remaining time.\n",
      "\t-0.2574       = Validation score (-WQL)\n",
      "\t1.45    s     = Training runtime\n",
      "\t0.86    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 447.1s of the 3576.6s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 70 time series (6.7%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2561       = Validation score (-WQL)\n",
      "\t4.37    s     = Training runtime\n",
      "\t4.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.7s of the 3568.2s of remaining time.\n",
      "\t-0.2451       = Validation score (-WQL)\n",
      "\t5.82    s     = Training runtime\n",
      "\t6.07    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 592.7s of the 3556.3s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250714_003531\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Maestria Ciencia de Datos\\Labo 3\\TP\\Dataset\\AutogluonModels\\ag-20250714_003531\\models\\ChronosFineTuned[bolt_small]\\W1\\fine-tuned-ckpt\n",
      "\t-0.2296       = Validation score (-WQL)\n",
      "\t525.11  s     = Training runtime\n",
      "\t1.13    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 607.5s of the 3030.0s of remaining time.\n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tPredictions contain NaN values.\n",
      "Training timeseries model DeepAR. Training for up to 805.3s of the 3015.9s of remaining time.\n",
      "\t-0.2499       = Validation score (-WQL)\n",
      "\t133.65  s     = Training runtime\n",
      "\t0.73    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1140.8s of the 2881.5s of remaining time.\n",
      "\t-0.2412       = Validation score (-WQL)\n",
      "\t115.80  s     = Training runtime\n",
      "\t0.45    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2165.2s of the 2765.2s of remaining time.\n",
      "\t-0.2825       = Validation score (-WQL)\n",
      "\t274.09  s     = Training runtime\n",
      "\t0.68    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.16, 'ChronosFineTuned[bolt_small]': 0.52, 'PatchTST': 0.28, 'RecursiveTabular': 0.03}\n",
      "\t-0.2258       = Validation score (-WQL)\n",
      "\t2.31    s     = Training runtime\n",
      "\t5.78    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 1112.03 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.2258\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n"
     ]
    }
   ],
   "source": [
    "# 1. PreparaciÃ³n de datos (sin cambios)\n",
    "df['timestamp'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "df['item_id'] = df['product_id']\n",
    "periods = sorted(df['timestamp'].unique())\n",
    "\n",
    "\n",
    "# 2. Loop de simulaciÃ³n de pronÃ³stico a futuro\n",
    "results = []\n",
    "min_length = 7\n",
    "# El bucle ahora puede empezar antes y llegar hasta el final\n",
    "for idx in range(min_length - 1, len(periods)):\n",
    "    # CAMBIO 1: El 'cutoff' es ahora el Ãºltimo dato conocido en cada iteraciÃ³n\n",
    "    cutoff = periods[idx]\n",
    "    \n",
    "    # CAMBIO 2: El 'target_period' se calcula, no se busca. Es 2 meses despuÃ©s del cutoff.\n",
    "    target_period = cutoff + pd.DateOffset(months=2)\n",
    "\n",
    "    df_train = df[df['timestamp'] <= cutoff]\n",
    "\n",
    "    # La lÃ³gica para validar IDs y rellenar faltantes no cambia\n",
    "    counts = df_train.groupby('item_id').size()\n",
    "    valid_ids = counts[counts >= min_length].index.tolist()\n",
    "    if not valid_ids:\n",
    "        continue\n",
    "\n",
    "    df_train = df_train[df_train['item_id'].isin(valid_ids)]\n",
    "    n_meses = df_train['timestamp'].nunique()\n",
    "    cutoff_str = pd.to_datetime(cutoff).strftime('%Y%m')\n",
    "\n",
    "    ts_train = TimeSeriesDataFrame.from_data_frame(\n",
    "        df_train,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp'\n",
    "    ).fill_missing_values()\n",
    "\n",
    "    # El predictor se entrena igual, para predecir 2 pasos\n",
    "    predictor = TimeSeriesPredictor(\n",
    "        prediction_length=2,\n",
    "        target='producto_total_tn',\n",
    "        freq='MS'\n",
    "    )\n",
    "    predictor.fit(ts_train, num_val_windows=2, time_limit=60*60)\n",
    "\n",
    "    # La predicciÃ³n genera pronÃ³sticos para (cutoff+1 mes) y (cutoff+2 meses)\n",
    "    forecast = predictor.predict(ts_train)\n",
    "    df_pred = forecast['mean'].reset_index().rename(columns={\n",
    "        'item_id': 'product_id',\n",
    "        'mean': 'tn_pred_auto'\n",
    "    })\n",
    "\n",
    "    # CAMBIO 3: Filtramos para quedarnos solo con la predicciÃ³n a 2 meses\n",
    "    df_pred = df_pred[df_pred['timestamp'] == target_period]\n",
    "\n",
    "    # Agregamos la informaciÃ³n del contexto de la predicciÃ³n\n",
    "    df_pred['n_meses_hist'] = n_meses\n",
    "    df_pred['periodo_pred'] = cutoff_str # Mes en que se generÃ³ la predicciÃ³n\n",
    "    results.append(df_pred[['product_id','periodo_pred', 'timestamp', 'tn_pred_auto', 'n_meses_hist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad36f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a77be9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo_pred</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tn_pred_auto</th>\n",
       "      <th>n_meses_hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>201707</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>1025.904886</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>201707</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>705.145762</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>201707</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>721.740799</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>201707</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>522.744958</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>201707</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>551.690417</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id periodo_pred  timestamp  tn_pred_auto  n_meses_hist\n",
       "0       20001       201707 2017-09-01   1025.904886             7\n",
       "1       20002       201707 2017-09-01    705.145762             7\n",
       "2       20003       201707 2017-09-01    721.740799             7\n",
       "3       20004       201707 2017-09-01    522.744958             7\n",
       "4       20005       201707 2017-09-01    551.690417             7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c51fd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>producto_total_tn</th>\n",
       "      <th>avg_tn</th>\n",
       "      <th>std_tn</th>\n",
       "      <th>clientes_distintos</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>inicio_vida_p</th>\n",
       "      <th>fin_vida_p</th>\n",
       "      <th>...</th>\n",
       "      <th>otros_avg_lag6</th>\n",
       "      <th>otros_avg_lag7</th>\n",
       "      <th>otros_avg_lag8</th>\n",
       "      <th>otros_avg_lag9</th>\n",
       "      <th>otros_avg_lag10</th>\n",
       "      <th>otros_avg_lag11</th>\n",
       "      <th>otros_avg_lag12</th>\n",
       "      <th>otros_avg_lag13</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>935.0</td>\n",
       "      <td>2.158203</td>\n",
       "      <td>13.507812</td>\n",
       "      <td>433</td>\n",
       "      <td>479</td>\n",
       "      <td>937.5</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201702</td>\n",
       "      <td>20001</td>\n",
       "      <td>798.0</td>\n",
       "      <td>1.645508</td>\n",
       "      <td>11.492188</td>\n",
       "      <td>485</td>\n",
       "      <td>432</td>\n",
       "      <td>833.5</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201703</td>\n",
       "      <td>20001</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>2.576172</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>506</td>\n",
       "      <td>509</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201704</td>\n",
       "      <td>20001</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>2.089844</td>\n",
       "      <td>17.906250</td>\n",
       "      <td>512</td>\n",
       "      <td>279</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201705</td>\n",
       "      <td>20001</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>2.927734</td>\n",
       "      <td>16.906250</td>\n",
       "      <td>513</td>\n",
       "      <td>701</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201706</td>\n",
       "      <td>20001</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>2.951172</td>\n",
       "      <td>18.218750</td>\n",
       "      <td>515</td>\n",
       "      <td>570</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201707</td>\n",
       "      <td>20001</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1.997070</td>\n",
       "      <td>18.218750</td>\n",
       "      <td>516</td>\n",
       "      <td>381</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>104.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201708</td>\n",
       "      <td>20001</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>2.433594</td>\n",
       "      <td>14.179688</td>\n",
       "      <td>521</td>\n",
       "      <td>643</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>110.4375</td>\n",
       "      <td>104.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201709</td>\n",
       "      <td>20001</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>2.507812</td>\n",
       "      <td>17.765625</td>\n",
       "      <td>525</td>\n",
       "      <td>381</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>145.2500</td>\n",
       "      <td>110.4375</td>\n",
       "      <td>104.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201710</td>\n",
       "      <td>20001</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>2.742188</td>\n",
       "      <td>23.968750</td>\n",
       "      <td>525</td>\n",
       "      <td>273</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>108.6250</td>\n",
       "      <td>145.2500</td>\n",
       "      <td>110.4375</td>\n",
       "      <td>104.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201711</td>\n",
       "      <td>20001</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>2.994141</td>\n",
       "      <td>16.187500</td>\n",
       "      <td>528</td>\n",
       "      <td>519</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>137.6250</td>\n",
       "      <td>108.6250</td>\n",
       "      <td>145.2500</td>\n",
       "      <td>110.4375</td>\n",
       "      <td>104.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201712</td>\n",
       "      <td>20001</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1.983398</td>\n",
       "      <td>12.546875</td>\n",
       "      <td>529</td>\n",
       "      <td>435</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>148.1250</td>\n",
       "      <td>137.6250</td>\n",
       "      <td>108.6250</td>\n",
       "      <td>145.2500</td>\n",
       "      <td>110.4375</td>\n",
       "      <td>104.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>201801</td>\n",
       "      <td>20001</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>2.210938</td>\n",
       "      <td>19.781250</td>\n",
       "      <td>529</td>\n",
       "      <td>437</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>112.6250</td>\n",
       "      <td>148.1250</td>\n",
       "      <td>137.6250</td>\n",
       "      <td>108.6250</td>\n",
       "      <td>145.2500</td>\n",
       "      <td>110.4375</td>\n",
       "      <td>104.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>201802</td>\n",
       "      <td>20001</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>1.969727</td>\n",
       "      <td>11.406250</td>\n",
       "      <td>530</td>\n",
       "      <td>302</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>108.3750</td>\n",
       "      <td>112.6250</td>\n",
       "      <td>148.1250</td>\n",
       "      <td>137.6250</td>\n",
       "      <td>108.6250</td>\n",
       "      <td>145.2500</td>\n",
       "      <td>110.4375</td>\n",
       "      <td>104.1250</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>201803</td>\n",
       "      <td>20001</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>3.490234</td>\n",
       "      <td>21.875000</td>\n",
       "      <td>532</td>\n",
       "      <td>591</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>...</td>\n",
       "      <td>123.6250</td>\n",
       "      <td>108.3750</td>\n",
       "      <td>112.6250</td>\n",
       "      <td>148.1250</td>\n",
       "      <td>137.6250</td>\n",
       "      <td>108.6250</td>\n",
       "      <td>145.2500</td>\n",
       "      <td>110.4375</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    periodo  product_id  producto_total_tn    avg_tn     std_tn  \\\n",
       "0    201701       20001              935.0  2.158203  13.507812   \n",
       "1    201702       20001              798.0  1.645508  11.492188   \n",
       "2    201703       20001             1303.0  2.576172  18.500000   \n",
       "3    201704       20001             1070.0  2.089844  17.906250   \n",
       "4    201705       20001             1502.0  2.927734  16.906250   \n",
       "5    201706       20001             1520.0  2.951172  18.218750   \n",
       "6    201707       20001             1031.0  1.997070  18.218750   \n",
       "7    201708       20001             1267.0  2.433594  14.179688   \n",
       "8    201709       20001             1317.0  2.507812  17.765625   \n",
       "9    201710       20001             1440.0  2.742188  23.968750   \n",
       "10   201711       20001             1580.0  2.994141  16.187500   \n",
       "11   201712       20001             1049.0  1.983398  12.546875   \n",
       "12   201801       20001             1169.0  2.210938  19.781250   \n",
       "13   201802       20001             1044.0  1.969727  11.406250   \n",
       "14   201803       20001             1857.0  3.490234  21.875000   \n",
       "\n",
       "    clientes_distintos  cust_request_qty  cust_request_tn  inicio_vida_p  \\\n",
       "0                  433               479            937.5         201701   \n",
       "1                  485               432            833.5         201701   \n",
       "2                  506               509           1331.0         201701   \n",
       "3                  512               279           1133.0         201701   \n",
       "4                  513               701           1551.0         201701   \n",
       "5                  515               570           1576.0         201701   \n",
       "6                  516               381           1086.0         201701   \n",
       "7                  521               643           1290.0         201701   \n",
       "8                  525               381           1357.0         201701   \n",
       "9                  525               273           1442.0         201701   \n",
       "10                 528               519           1587.0         201701   \n",
       "11                 529               435           1099.0         201701   \n",
       "12                 529               437           1256.0         201701   \n",
       "13                 530               302           1150.0         201701   \n",
       "14                 532               591           1903.0         201701   \n",
       "\n",
       "    fin_vida_p  ... otros_avg_lag6 otros_avg_lag7 otros_avg_lag8  \\\n",
       "0       201912  ...            NaN            NaN            NaN   \n",
       "1       201912  ...            NaN            NaN            NaN   \n",
       "2       201912  ...            NaN            NaN            NaN   \n",
       "3       201912  ...            NaN            NaN            NaN   \n",
       "4       201912  ...            NaN            NaN            NaN   \n",
       "5       201912  ...            NaN            NaN            NaN   \n",
       "6       201912  ...       104.1250            NaN            NaN   \n",
       "7       201912  ...       110.4375       104.1250            NaN   \n",
       "8       201912  ...       145.2500       110.4375       104.1250   \n",
       "9       201912  ...       108.6250       145.2500       110.4375   \n",
       "10      201912  ...       137.6250       108.6250       145.2500   \n",
       "11      201912  ...       148.1250       137.6250       108.6250   \n",
       "12      201912  ...       112.6250       148.1250       137.6250   \n",
       "13      201912  ...       108.3750       112.6250       148.1250   \n",
       "14      201912  ...       123.6250       108.3750       112.6250   \n",
       "\n",
       "   otros_avg_lag9  otros_avg_lag10  otros_avg_lag11  otros_avg_lag12  \\\n",
       "0             NaN              NaN              NaN              NaN   \n",
       "1             NaN              NaN              NaN              NaN   \n",
       "2             NaN              NaN              NaN              NaN   \n",
       "3             NaN              NaN              NaN              NaN   \n",
       "4             NaN              NaN              NaN              NaN   \n",
       "5             NaN              NaN              NaN              NaN   \n",
       "6             NaN              NaN              NaN              NaN   \n",
       "7             NaN              NaN              NaN              NaN   \n",
       "8             NaN              NaN              NaN              NaN   \n",
       "9        104.1250              NaN              NaN              NaN   \n",
       "10       110.4375         104.1250              NaN              NaN   \n",
       "11       145.2500         110.4375         104.1250              NaN   \n",
       "12       108.6250         145.2500         110.4375         104.1250   \n",
       "13       137.6250         108.6250         145.2500         110.4375   \n",
       "14       148.1250         137.6250         108.6250         145.2500   \n",
       "\n",
       "    otros_avg_lag13  timestamp  item_id  \n",
       "0               NaN 2017-01-01    20001  \n",
       "1               NaN 2017-02-01    20001  \n",
       "2               NaN 2017-03-01    20001  \n",
       "3               NaN 2017-04-01    20001  \n",
       "4               NaN 2017-05-01    20001  \n",
       "5               NaN 2017-06-01    20001  \n",
       "6               NaN 2017-07-01    20001  \n",
       "7               NaN 2017-08-01    20001  \n",
       "8               NaN 2017-09-01    20001  \n",
       "9               NaN 2017-10-01    20001  \n",
       "10              NaN 2017-11-01    20001  \n",
       "11              NaN 2017-12-01    20001  \n",
       "12              NaN 2018-01-01    20001  \n",
       "13         104.1250 2018-02-01    20001  \n",
       "14         110.4375 2018-03-01    20001  \n",
       "\n",
       "[15 rows x 302 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d98ec3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds.to_parquet('predicciones_autogluon.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5847645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds.to_csv('predicciones_autogluon.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d334b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds['periodo'] = df_all_preds['timestamp'].dt.strftime('%Y%m').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66a57320",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_all_preds['periodo_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac043134",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['timestamp']\n",
    "del df['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f866f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.merge(\n",
    "   df_all_preds,\n",
    "    on=['product_id','periodo'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d43795ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31522, 303)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7dfaeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uso de memoria inicial del DataFrame: 19.40 MB\n",
      "Uso de memoria final del DataFrame: 18.53 MB\n",
      "Memoria reducida en un 4.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\3492438140.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(df[col]):\n",
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\3492438140.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(df[col]):\n",
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\3492438140.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(df[col]):\n",
      "C:\\Users\\diana\\AppData\\Local\\Temp\\ipykernel_7720\\3492438140.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(df[col]):\n"
     ]
    }
   ],
   "source": [
    "df_final['tn_pred_auto_delta_a_tn']=df_final['tn_pred_auto']-df['producto_total_tn'].fillna(0)\n",
    "df_final['ratio_tn_pred_auto_delta_a_tn']=percentage_safe(df_final['tn_pred_auto_delta_a_tn'],df['producto_total_tn'])\n",
    "df_final['ratio_tn_pred_a_tn']=percentage_safe(df_final['tn_pred_auto'],df['producto_total_tn'])\n",
    "\n",
    "df_final=reduce_mem_usage(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6537b046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>producto_total_tn</th>\n",
       "      <th>tn_pred_auto</th>\n",
       "      <th>tn_pred_auto_delta_a_tn</th>\n",
       "      <th>ratio_tn_pred_auto_delta_a_tn</th>\n",
       "      <th>ratio_tn_pred_a_tn</th>\n",
       "      <th>n_meses_hist</th>\n",
       "      <th>clase_producto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>935.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201702</td>\n",
       "      <td>20001</td>\n",
       "      <td>798.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201703</td>\n",
       "      <td>20001</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201704</td>\n",
       "      <td>20001</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201705</td>\n",
       "      <td>20001</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201706</td>\n",
       "      <td>20001</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201707</td>\n",
       "      <td>20001</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201708</td>\n",
       "      <td>20001</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201709</td>\n",
       "      <td>20001</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>-291.000000</td>\n",
       "      <td>-0.221069</td>\n",
       "      <td>0.778809</td>\n",
       "      <td>7.0</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201710</td>\n",
       "      <td>20001</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>-287.250000</td>\n",
       "      <td>-0.199463</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201711</td>\n",
       "      <td>20001</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>-426.250000</td>\n",
       "      <td>-0.269775</td>\n",
       "      <td>0.729980</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201712</td>\n",
       "      <td>20001</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>1.291016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>201801</td>\n",
       "      <td>20001</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>169.125000</td>\n",
       "      <td>0.144653</td>\n",
       "      <td>1.144531</td>\n",
       "      <td>11.0</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>201802</td>\n",
       "      <td>20001</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>187.375000</td>\n",
       "      <td>0.179565</td>\n",
       "      <td>1.179688</td>\n",
       "      <td>12.0</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>201803</td>\n",
       "      <td>20001</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>-760.000000</td>\n",
       "      <td>-0.409424</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>201804</td>\n",
       "      <td>20001</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>979.5</td>\n",
       "      <td>-271.250000</td>\n",
       "      <td>-0.216919</td>\n",
       "      <td>0.783203</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>201805</td>\n",
       "      <td>20001</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>38.468750</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>1.029297</td>\n",
       "      <td>15.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>201806</td>\n",
       "      <td>20001</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>168.375000</td>\n",
       "      <td>0.146362</td>\n",
       "      <td>1.146484</td>\n",
       "      <td>16.0</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>201807</td>\n",
       "      <td>20001</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>-342.750000</td>\n",
       "      <td>-0.233154</td>\n",
       "      <td>0.766602</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>201808</td>\n",
       "      <td>20001</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>-539.500000</td>\n",
       "      <td>-0.299561</td>\n",
       "      <td>0.700684</td>\n",
       "      <td>18.0</td>\n",
       "      <td>495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>201809</td>\n",
       "      <td>20001</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>-129.625000</td>\n",
       "      <td>-0.090088</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>19.0</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>201810</td>\n",
       "      <td>20001</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>-883.000000</td>\n",
       "      <td>-0.384521</td>\n",
       "      <td>0.615723</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>201811</td>\n",
       "      <td>20001</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>-532.500000</td>\n",
       "      <td>-0.293701</td>\n",
       "      <td>0.706543</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>201812</td>\n",
       "      <td>20001</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>-43.937500</td>\n",
       "      <td>-0.029541</td>\n",
       "      <td>0.970215</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>201901</td>\n",
       "      <td>20001</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>159.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>201902</td>\n",
       "      <td>20001</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>-89.437500</td>\n",
       "      <td>-0.071045</td>\n",
       "      <td>0.928711</td>\n",
       "      <td>24.0</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>201903</td>\n",
       "      <td>20001</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>-340.250000</td>\n",
       "      <td>-0.231201</td>\n",
       "      <td>0.768555</td>\n",
       "      <td>25.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>201904</td>\n",
       "      <td>20001</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>-420.750000</td>\n",
       "      <td>-0.255127</td>\n",
       "      <td>0.744629</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>201905</td>\n",
       "      <td>20001</td>\n",
       "      <td>1630.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>-372.500000</td>\n",
       "      <td>-0.228516</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>27.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>201906</td>\n",
       "      <td>20001</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>341.500000</td>\n",
       "      <td>0.307617</td>\n",
       "      <td>1.307617</td>\n",
       "      <td>28.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>201907</td>\n",
       "      <td>20001</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>-198.125000</td>\n",
       "      <td>-0.117981</td>\n",
       "      <td>0.881836</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>201908</td>\n",
       "      <td>20001</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>171.250000</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>1.135742</td>\n",
       "      <td>30.0</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>201909</td>\n",
       "      <td>20001</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>-200.500000</td>\n",
       "      <td>-0.120789</td>\n",
       "      <td>0.879395</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>201910</td>\n",
       "      <td>20001</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>-240.000000</td>\n",
       "      <td>-0.153687</td>\n",
       "      <td>0.846191</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>201911</td>\n",
       "      <td>20001</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>60.343750</td>\n",
       "      <td>0.043182</td>\n",
       "      <td>1.042969</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>201912</td>\n",
       "      <td>20001</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>-41.250000</td>\n",
       "      <td>-0.027420</td>\n",
       "      <td>0.972656</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>201701</td>\n",
       "      <td>20002</td>\n",
       "      <td>550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>201702</td>\n",
       "      <td>20002</td>\n",
       "      <td>506.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>201703</td>\n",
       "      <td>20002</td>\n",
       "      <td>834.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>201704</td>\n",
       "      <td>20002</td>\n",
       "      <td>522.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>201705</td>\n",
       "      <td>20002</td>\n",
       "      <td>843.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>201706</td>\n",
       "      <td>20002</td>\n",
       "      <td>968.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-348.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>201707</td>\n",
       "      <td>20002</td>\n",
       "      <td>845.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>201708</td>\n",
       "      <td>20002</td>\n",
       "      <td>619.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>201709</td>\n",
       "      <td>20002</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>-359.750000</td>\n",
       "      <td>-0.337891</td>\n",
       "      <td>0.662109</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-314.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>201710</td>\n",
       "      <td>20002</td>\n",
       "      <td>857.5</td>\n",
       "      <td>680.5</td>\n",
       "      <td>-177.125000</td>\n",
       "      <td>-0.206543</td>\n",
       "      <td>0.793457</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>201711</td>\n",
       "      <td>20002</td>\n",
       "      <td>750.5</td>\n",
       "      <td>743.5</td>\n",
       "      <td>-6.980469</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>0.990723</td>\n",
       "      <td>9.0</td>\n",
       "      <td>234.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>201712</td>\n",
       "      <td>20002</td>\n",
       "      <td>820.5</td>\n",
       "      <td>825.0</td>\n",
       "      <td>4.691406</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>1.005859</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-108.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>201801</td>\n",
       "      <td>20002</td>\n",
       "      <td>985.0</td>\n",
       "      <td>782.5</td>\n",
       "      <td>-202.500000</td>\n",
       "      <td>-0.205566</td>\n",
       "      <td>0.794434</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>201802</td>\n",
       "      <td>20002</td>\n",
       "      <td>712.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>86.875000</td>\n",
       "      <td>0.122009</td>\n",
       "      <td>1.122070</td>\n",
       "      <td>12.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    periodo  product_id  producto_total_tn  tn_pred_auto  \\\n",
       "0    201701       20001              935.0           NaN   \n",
       "1    201702       20001              798.0           NaN   \n",
       "2    201703       20001             1303.0           NaN   \n",
       "3    201704       20001             1070.0           NaN   \n",
       "4    201705       20001             1502.0           NaN   \n",
       "5    201706       20001             1520.0           NaN   \n",
       "6    201707       20001             1031.0           NaN   \n",
       "7    201708       20001             1267.0           NaN   \n",
       "8    201709       20001             1317.0        1026.0   \n",
       "9    201710       20001             1440.0        1153.0   \n",
       "10   201711       20001             1580.0        1154.0   \n",
       "11   201712       20001             1049.0        1354.0   \n",
       "12   201801       20001             1169.0        1338.0   \n",
       "13   201802       20001             1044.0        1231.0   \n",
       "14   201803       20001             1857.0        1097.0   \n",
       "15   201804       20001             1251.0         979.5   \n",
       "16   201805       20001             1294.0        1332.0   \n",
       "17   201806       20001             1151.0        1319.0   \n",
       "18   201807       20001             1470.0        1127.0   \n",
       "19   201808       20001             1801.0        1262.0   \n",
       "20   201809       20001             1439.0        1309.0   \n",
       "21   201810       20001             2296.0        1413.0   \n",
       "22   201811       20001             1813.0        1281.0   \n",
       "23   201812       20001             1487.0        1443.0   \n",
       "24   201901       20001             1276.0        1435.0   \n",
       "25   201902       20001             1259.0        1170.0   \n",
       "26   201903       20001             1471.0        1131.0   \n",
       "27   201904       20001             1648.0        1227.0   \n",
       "28   201905       20001             1630.0        1258.0   \n",
       "29   201906       20001             1110.0        1452.0   \n",
       "30   201907       20001             1679.0        1481.0   \n",
       "31   201908       20001             1261.0        1432.0   \n",
       "32   201909       20001             1660.0        1460.0   \n",
       "33   201910       20001             1562.0        1322.0   \n",
       "34   201911       20001             1397.0        1457.0   \n",
       "35   201912       20001             1505.0        1464.0   \n",
       "36   201701       20002              550.0           NaN   \n",
       "37   201702       20002              506.0           NaN   \n",
       "38   201703       20002              834.5           NaN   \n",
       "39   201704       20002              522.5           NaN   \n",
       "40   201705       20002              843.5           NaN   \n",
       "41   201706       20002              968.0           NaN   \n",
       "42   201707       20002              845.5           NaN   \n",
       "43   201708       20002              619.5           NaN   \n",
       "44   201709       20002             1065.0         705.0   \n",
       "45   201710       20002              857.5         680.5   \n",
       "46   201711       20002              750.5         743.5   \n",
       "47   201712       20002              820.5         825.0   \n",
       "48   201801       20002              985.0         782.5   \n",
       "49   201802       20002              712.0         799.0   \n",
       "\n",
       "    tn_pred_auto_delta_a_tn  ratio_tn_pred_auto_delta_a_tn  \\\n",
       "0                       NaN                            NaN   \n",
       "1                       NaN                            NaN   \n",
       "2                       NaN                            NaN   \n",
       "3                       NaN                            NaN   \n",
       "4                       NaN                            NaN   \n",
       "5                       NaN                            NaN   \n",
       "6                       NaN                            NaN   \n",
       "7                       NaN                            NaN   \n",
       "8               -291.000000                      -0.221069   \n",
       "9               -287.250000                      -0.199463   \n",
       "10              -426.250000                      -0.269775   \n",
       "11               305.000000                       0.290771   \n",
       "12               169.125000                       0.144653   \n",
       "13               187.375000                       0.179565   \n",
       "14              -760.000000                      -0.409424   \n",
       "15              -271.250000                      -0.216919   \n",
       "16                38.468750                       0.029724   \n",
       "17               168.375000                       0.146362   \n",
       "18              -342.750000                      -0.233154   \n",
       "19              -539.500000                      -0.299561   \n",
       "20              -129.625000                      -0.090088   \n",
       "21              -883.000000                      -0.384521   \n",
       "22              -532.500000                      -0.293701   \n",
       "23               -43.937500                      -0.029541   \n",
       "24               159.500000                       0.125000   \n",
       "25               -89.437500                      -0.071045   \n",
       "26              -340.250000                      -0.231201   \n",
       "27              -420.750000                      -0.255127   \n",
       "28              -372.500000                      -0.228516   \n",
       "29               341.500000                       0.307617   \n",
       "30              -198.125000                      -0.117981   \n",
       "31               171.250000                       0.135864   \n",
       "32              -200.500000                      -0.120789   \n",
       "33              -240.000000                      -0.153687   \n",
       "34                60.343750                       0.043182   \n",
       "35               -41.250000                      -0.027420   \n",
       "36                      NaN                            NaN   \n",
       "37                      NaN                            NaN   \n",
       "38                      NaN                            NaN   \n",
       "39                      NaN                            NaN   \n",
       "40                      NaN                            NaN   \n",
       "41                      NaN                            NaN   \n",
       "42                      NaN                            NaN   \n",
       "43                      NaN                            NaN   \n",
       "44              -359.750000                      -0.337891   \n",
       "45              -177.125000                      -0.206543   \n",
       "46                -6.980469                      -0.009300   \n",
       "47                 4.691406                       0.005718   \n",
       "48              -202.500000                      -0.205566   \n",
       "49                86.875000                       0.122009   \n",
       "\n",
       "    ratio_tn_pred_a_tn  n_meses_hist  clase_producto  \n",
       "0                  NaN           NaN           368.0  \n",
       "1                  NaN           NaN           272.0  \n",
       "2                  NaN           NaN           199.0  \n",
       "3                  NaN           NaN           450.0  \n",
       "4                  NaN           NaN          -471.0  \n",
       "5                  NaN           NaN          -253.0  \n",
       "6                  NaN           NaN           286.0  \n",
       "7                  NaN           NaN           173.0  \n",
       "8             0.778809           7.0           263.0  \n",
       "9             0.800781           8.0          -391.0  \n",
       "10            0.729980           9.0          -411.0  \n",
       "11            1.291016          10.0            -5.0  \n",
       "12            1.144531          11.0           688.0  \n",
       "13            1.179688          12.0           207.0  \n",
       "14            0.590820          13.0          -563.0  \n",
       "15            0.783203          14.0          -100.0  \n",
       "16            1.029297          15.0           176.0  \n",
       "17            1.146484          16.0           650.0  \n",
       "18            0.766602          17.0           -31.0  \n",
       "19            0.700684          18.0           495.0  \n",
       "20            0.910156          19.0           374.0  \n",
       "21            0.615723          20.0          -809.0  \n",
       "22            0.706543          21.0          -537.0  \n",
       "23            0.970215          22.0          -228.0  \n",
       "24            1.125000          23.0           195.0  \n",
       "25            0.928711          24.0           389.0  \n",
       "26            0.768555          25.0           159.0  \n",
       "27            0.744629          26.0          -538.0  \n",
       "28            0.771484          27.0            49.0  \n",
       "29            1.307617          28.0           151.0  \n",
       "30            0.881836          29.0           -19.0  \n",
       "31            1.135742          30.0           301.0  \n",
       "32            0.879395          31.0          -263.0  \n",
       "33            0.846191          32.0           -57.0  \n",
       "34            1.042969          33.0             0.0  \n",
       "35            0.972656          34.0             0.0  \n",
       "36                 NaN           NaN           284.5  \n",
       "37                 NaN           NaN            16.5  \n",
       "38                 NaN           NaN             9.0  \n",
       "39                 NaN           NaN           445.5  \n",
       "40                 NaN           NaN             2.0  \n",
       "41                 NaN           NaN          -348.5  \n",
       "42                 NaN           NaN           219.5  \n",
       "43                 NaN           NaN           238.0  \n",
       "44            0.662109           7.0          -314.5  \n",
       "45            0.793457           8.0           -37.0  \n",
       "46            0.990723           9.0           234.5  \n",
       "47            1.005859          10.0          -108.5  \n",
       "48            0.794434          11.0           -18.0  \n",
       "49            1.122070          12.0           287.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['periodo','product_id','producto_total_tn','tn_pred_auto','tn_pred_auto_delta_a_tn','ratio_tn_pred_auto_delta_a_tn','ratio_tn_pred_a_tn','n_meses_hist','clase_producto']].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578c3c5",
   "metadata": {},
   "source": [
    "# Exportar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a278683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet('1_b_producto_autogluon.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7aea463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_final.head(1000).to_excel('01b_producto_autogluon.xlsx',sheet_name='hoja1',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fafedf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame de entrenamiento guardado en 'train.parquet' con 31021 filas.\n"
     ]
    }
   ],
   "source": [
    "#df_train = df[~df['periodo'].isin([201911, 201912])]\n",
    "#df_train = df_final.query(\"periodo != 201911 and periodo != 201912\")\n",
    "\n",
    "#df_train.to_parquet('train_producto_autogluon.parquet', index=False)\n",
    "print(f\"DataFrame de entrenamiento guardado en 'train.parquet' con {len(df_train)} filas.\")\n",
    "\n",
    "# --- 3. Preparar y guardar el DataFrame de predicciÃ³n en Parquet ---\n",
    "# Seleccionamos los periodos 201911 y 201912 para el conjunto de predicciÃ³n.\n",
    "# Eliminamos la columna 'clase' ya que no serÃ¡ necesaria para la predicciÃ³n.\n",
    "# Finalmente, guardamos este DataFrame en un archivo Parquet.\n",
    "#df_predecir = df_final[df_final['periodo'].isin([201911, 201912])].copy() # Usar .copy() para evitar SettingWithCopyWarning\n",
    "#df_predecir.drop(columns=['clase'], inplace=True)\n",
    "#df_predecir.to_parquet('predecir_producto_autogluon.parquet', index=False)\n",
    "#print(f\"DataFrame para predicciÃ³n guardado en 'predecir.parquet' con {len(df_predecir)} filas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
